{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project_Image_Processing__DE_K19_BY_PJ_Mamipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0Oud4KTz3w2",
        "outputId": "51c05e1e-c794-44e1-d37c-3bf88b8b14bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "# 0. Link colab với Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd /content/gdrive/MyDrive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.Convert XML label sang CSV. File CSV lưu trong thư mục split_data\n",
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "\n",
        "def xml_to_csv(path):\n",
        "    xml_list = []\n",
        "    for xml_file in glob.glob(path + '/*.xml'):\n",
        "        tree = ET.parse(xml_file)\n",
        "        root = tree.getroot()\n",
        "        for member in root.findall('object'):\n",
        "            value = (root.find('filename').text,\n",
        "                     int(root.find('size')[0].text),\n",
        "                     int(root.find('size')[1].text),\n",
        "                     member[0].text,\n",
        "                     int(member[4][0].text),\n",
        "                     int(member[4][1].text),\n",
        "                     int(member[4][2].text),\n",
        "                     int(member[4][3].text)\n",
        "                     )\n",
        "            xml_list.append(value)\n",
        "    column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "    xml_df = pd.DataFrame(xml_list, columns=column_name)\n",
        "    return xml_df\n",
        "\n",
        "for directory in ['train','test']:\n",
        "        image_path = os.path.join('/content/gdrive/MyDrive/data/split_data/{}'.format(directory))\n",
        "        xml_df = xml_to_csv(image_path)\n",
        "        xml_df.to_csv('/content/gdrive/MyDrive/data/split_data/{}_labels.csv'.format(directory), index=None)\n",
        "        print('Successfully converted xml to csv.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w939ALTs0Hv6",
        "outputId": "6dd7254e-6e0a-43c8-a4ea-0a1d2ec003ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully converted xml to csv.\n",
            "Successfully converted xml to csv.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Tải TF Object Detection APi vào thư mục models\n",
        "%cd /content/gdrive/MyDrive\n",
        "!git clone https://github.com/tensorflow/models.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PCYOujJ0MaI",
        "outputId": "222ea6c6-2aca-4131-de4d-cce71099fda1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive\n",
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 74167, done.\u001b[K\n",
            "remote: Counting objects: 100% (253/253), done.\u001b[K\n",
            "remote: Compressing objects: 100% (157/157), done.\u001b[K\n",
            "remote: Total 74167 (delta 112), reused 212 (delta 87), pack-reused 73914\u001b[K\n",
            "Receiving objects: 100% (74167/74167), 580.17 MiB | 16.61 MiB/s, done.\n",
            "Resolving deltas: 100% (52524/52524), done.\n",
            "Checking out files: 100% (3080/3080), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Compile the protos -  \n",
        "# Protocol Buffers (Protobuf) is a free and open-source cross-platform data format used to serialize structured data.\n",
        "%cd /content/gdrive/MyDrive/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zfrLdyd0UUR",
        "outputId": "a16698fc-2d7d-49e5-ec2a-ad66de53f6ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/models/research\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Cài dặt API\n",
        "%cd /content/gdrive/MyDrive/models/research\n",
        "!cp object_detection/packages/tf2/setup.py . \n",
        "!python -m pip install ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIZayzp_0diN",
        "outputId": "2941b774-18b9-4455-a3dc-ace0fb0edcd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/models/research\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/gdrive/MyDrive/models/research\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Collecting avro-python3\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "Collecting apache-beam\n",
            "  Downloading apache_beam-2.39.0-cp37-cp37m-manylinux2010_x86_64.whl (10.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.3 MB 8.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.30)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Collecting tf-slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[K     |████████████████████████████████| 352 kB 69.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.4)\n",
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.3.5)\n",
            "Collecting tf-models-official>=2.5.1\n",
            "  Downloading tf_models_official-2.9.2-py2.py3-none-any.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 53.0 MB/s \n",
            "\u001b[?25hCollecting tensorflow_io\n",
            "  Downloading tensorflow_io-0.26.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (25.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.9 MB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.8.0)\n",
            "Collecting pyparsing==2.4.7\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 7.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
            "Collecting tensorflow-model-optimization>=0.4.1\n",
            "  Downloading tensorflow_model_optimization-0.7.2-py2.py3-none-any.whl (237 kB)\n",
            "\u001b[K     |████████████████████████████████| 237 kB 58.7 MB/s \n",
            "\u001b[?25hCollecting sacrebleu\n",
            "  Downloading sacrebleu-2.1.0-py3-none-any.whl (92 kB)\n",
            "\u001b[K     |████████████████████████████████| 92 kB 13.9 MB/s \n",
            "\u001b[?25hCollecting tensorflow~=2.9.0\n",
            "  Downloading tensorflow-2.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 511.7 MB 6.4 kB/s \n",
            "\u001b[?25hCollecting py-cpuinfo>=3.3.0\n",
            "  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
            "\u001b[K     |████████████████████████████████| 99 kB 9.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.17.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 16.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.21.6)\n",
            "Collecting tensorflow-text~=2.9.0\n",
            "  Downloading tensorflow_text-2.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.6 MB 55.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 57.7 MB/s \n",
            "\u001b[?25hCollecting opencv-python-headless\n",
            "  Downloading opencv_python_headless-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 47.8 MB 1.4 MB/s \n",
            "\u001b[?25hCollecting pyyaml<6.0,>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 62.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.0.1)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.11)\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.0.4)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n",
            "Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.31.6)\n",
            "Requirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.35.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.17.4)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.56.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2022.1)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (21.3)\n",
            "Requirement already satisfied: protobuf<4.0.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.17.3)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.64.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (6.1.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2022.5.18.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n",
            "Collecting flatbuffers<2,>=1.12\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Collecting keras\n",
            "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 50.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.46.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.26.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (4.2.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
            "Collecting tensorboard<2.10,>=2.9\n",
            "  Downloading tensorboard-2.9.0-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 51.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (14.0.1)\n",
            "Collecting gast<=0.4.0,>=0.2.1\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
            "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[K     |████████████████████████████████| 438 kB 67.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.14.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.7)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.8.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.7)\n",
            "Collecting orjson<4.0\n",
            "  Downloading orjson-3.7.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (256 kB)\n",
            "\u001b[K     |████████████████████████████████| 256 kB 75.4 MB/s \n",
            "\u001b[?25hCollecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading hdfs-2.7.0-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Collecting fastavro<2,>=0.23.6\n",
            "  Downloading fastavro-1.4.12-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 58.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow<8.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (6.0.1)\n",
            "Collecting requests<3.0.0dev,>=2.18.0\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n",
            "\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[K     |████████████████████████████████| 151 kB 80.1 MB/s \n",
            "\u001b[?25hCollecting pymongo<4.0.0,>=3.8.0\n",
            "  Downloading pymongo-3.12.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (508 kB)\n",
            "\u001b[K     |████████████████████████████████| 508 kB 67.0 MB/s \n",
            "\u001b[?25hCollecting proto-plus<2,>=1.7.1\n",
            "  Downloading proto_plus-1.20.5-py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 4.5 MB/s \n",
            "\u001b[?25hCollecting cloudpickle<3,>=2.0.0\n",
            "  Downloading cloudpickle-2.1.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
            "Collecting protobuf<4.0.0dev,>=3.12.0\n",
            "  Downloading protobuf-3.19.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 55.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.0.12)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.4.2)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.8.9)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2019.12.20)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.16.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.7.1)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.8.0)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (21.4.0)\n",
            "Building wheels for collected packages: object-detection, py-cpuinfo, dill, avro-python3, seqeval\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1692505 sha256=cc060d21f598bf973dfa36804bcf9bdd362e1869acacdfe5118b0855be29f977\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-7mo2rdh7/wheels/d0/e3/e9/b9ffe85019ec441e90d8ff9eddee9950c4c23b7598204390b9\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22257 sha256=fc0577d56ec954f4b101beef69f496c0d642eb632da9b42dac1c02844be271fd\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78544 sha256=8007bb18f7b33cc4e664fa198a6837095bbb443056a98dee11caab33368bd22d\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44010 sha256=2fad7dcee59eb8d2079da39621749975fc6fafb64b41f90032d5dbd3f599a07d\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/e5/b1/6b151d9b535ee50aaa6ab27d145a0104b6df02e5636f0376da\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=763c316411ef03fa344a26a0cdf51e4717fd5e5aca101d4aed6b7faafd133a22\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built object-detection py-cpuinfo dill avro-python3 seqeval\n",
            "Installing collected packages: requests, pyparsing, protobuf, tensorflow-estimator, tensorboard, keras, gast, flatbuffers, tensorflow, portalocker, dill, colorama, tf-slim, tensorflow-text, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, pymongo, py-cpuinfo, proto-plus, orjson, opencv-python-headless, hdfs, fastavro, cloudpickle, tf-models-official, tensorflow-io, lvis, avro-python3, apache-beam, object-detection\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.9\n",
            "    Uninstalling pyparsing-3.0.9:\n",
            "      Successfully uninstalled pyparsing-3.0.9\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.17.3\n",
            "    Uninstalling protobuf-3.17.3:\n",
            "      Successfully uninstalled protobuf-3.17.3\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0\n",
            "    Uninstalling flatbuffers-2.0:\n",
            "      Successfully uninstalled flatbuffers-2.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.2+zzzcolab20220527125636\n",
            "    Uninstalling tensorflow-2.8.2+zzzcolab20220527125636:\n",
            "      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220527125636\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.5.1\n",
            "    Uninstalling dill-0.3.5.1:\n",
            "      Successfully uninstalled dill-0.3.5.1\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: pymongo\n",
            "    Found existing installation: pymongo 4.1.1\n",
            "    Uninstalling pymongo-4.1.1:\n",
            "      Successfully uninstalled pymongo-4.1.1\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 1.3.0\n",
            "    Uninstalling cloudpickle-1.3.0:\n",
            "      Successfully uninstalled cloudpickle-1.3.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "multiprocess 0.70.13 requires dill>=0.3.5.1, but you have dill 0.3.1.1 which is incompatible.\n",
            "gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.1.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed apache-beam-2.39.0 avro-python3-1.10.2 cloudpickle-2.1.0 colorama-0.4.4 dill-0.3.1.1 fastavro-1.4.12 flatbuffers-1.12 gast-0.4.0 hdfs-2.7.0 keras-2.9.0 lvis-0.5.3 object-detection-0.1 opencv-python-headless-4.5.5.64 orjson-3.7.0 portalocker-2.4.0 proto-plus-1.20.5 protobuf-3.19.4 py-cpuinfo-8.0.0 pymongo-3.12.3 pyparsing-2.4.7 pyyaml-5.4.1 requests-2.27.1 sacrebleu-2.1.0 sentencepiece-0.1.96 seqeval-1.2.2 tensorboard-2.9.0 tensorflow-2.9.1 tensorflow-addons-0.17.0 tensorflow-estimator-2.9.0 tensorflow-io-0.26.0 tensorflow-model-optimization-0.7.2 tensorflow-text-2.9.0 tf-models-official-2.9.2 tf-slim-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.8\n",
        "!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTS3x0mU0g6D",
        "outputId": "56ca9586-9199-4651-daf1-a7224c057234"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.8\n",
            "  Downloading https://us-python.pkg.dev/colab-wheels/public/tensorflow/tensorflow-2.8.0%2Bzzzcolab20220506162203-cp37-cp37m-linux_x86_64.whl\n",
            "\u001b[K     / 668.3 MB 86.8 MB/s\n",
            "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.15.0)\n",
            "Collecting keras<2.9,>=2.8.0rc0\n",
            "  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (4.2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (0.26.0)\n",
            "Collecting tensorboard<2.9,>=2.8\n",
            "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 52.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (0.4.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.46.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (3.3.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.21.6)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.6.3)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 66.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (3.19.4)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.14.1)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (14.0.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (57.4.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.0.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.12)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.1.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (3.1.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow==2.8) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow==2.8) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (2.27.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (3.3.7)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (0.6.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow==2.8) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow==2.8) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (0.4.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (1.24.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8) (3.2.0)\n",
            "Installing collected packages: tf-estimator-nightly, tensorboard, keras, tensorflow\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.0\n",
            "    Uninstalling tensorboard-2.9.0:\n",
            "      Successfully uninstalled tensorboard-2.9.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.1\n",
            "    Uninstalling tensorflow-2.9.1:\n",
            "      Successfully uninstalled tensorflow-2.9.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-models-official 2.9.2 requires tensorflow~=2.9.0, but you have tensorflow 2.8.0+zzzcolab20220506162203 which is incompatible.\n",
            "tensorflow-text 2.9.0 requires tensorflow<2.10,>=2.9.0; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.8.0+zzzcolab20220506162203 which is incompatible.\u001b[0m\n",
            "Successfully installed keras-2.8.0 tensorboard-2.8.0 tensorflow-2.8.0+zzzcolab20220506162203 tf-estimator-nightly-2.8.0.dev2021122109\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following packages will be REMOVED:\n",
            "  libcudnn8-dev\n",
            "The following held packages will be changed:\n",
            "  libcudnn8\n",
            "The following packages will be upgraded:\n",
            "  libcudnn8\n",
            "1 upgraded, 0 newly installed, 1 to remove and 43 not upgraded.\n",
            "Need to get 430 MB of archives.\n",
            "After this operation, 3,139 MB disk space will be freed.\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcudnn8 8.1.0.77-1+cuda11.2 [430 MB]\n",
            "Fetched 430 MB in 9s (49.0 MB/s)\n",
            "(Reading database ... 155632 files and directories currently installed.)\n",
            "Removing libcudnn8-dev (8.0.5.39-1+cuda11.1) ...\n",
            "(Reading database ... 155610 files and directories currently installed.)\n",
            "Preparing to unpack .../libcudnn8_8.1.0.77-1+cuda11.2_amd64.deb ...\n",
            "Unpacking libcudnn8 (8.1.0.77-1+cuda11.2) over (8.0.5.39-1+cuda11.1) ...\n",
            "Setting up libcudnn8 (8.1.0.77-1+cuda11.2) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Test API\n",
        "!python object_detection/builders/model_builder_tf2_test.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hA8QaVCJ0mF7",
        "outputId": "46fbe4d8-59b4-4055-c4a8-bf830c760add"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running tests under Python 3.7.13: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "2022-06-03 04:33:07.363392: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "W0603 04:33:07.577462 140058304223104 model_builder.py:1102] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.4s\n",
            "I0603 04:33:07.927290 140058304223104 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.4s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.49s\n",
            "I0603 04:33:08.416679 140058304223104 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.49s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.25s\n",
            "I0603 04:33:08.670235 140058304223104 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.25s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.23s\n",
            "I0603 04:33:08.896403 140058304223104 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.23s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.9s\n",
            "I0603 04:33:10.801666 140058304223104 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.9s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I0603 04:33:10.802696 140058304223104 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
            "I0603 04:33:10.823628 140058304223104 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
            "I0603 04:33:10.836673 140058304223104 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
            "I0603 04:33:10.850771 140058304223104 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.09s\n",
            "I0603 04:33:10.943582 140058304223104 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.08s\n",
            "I0603 04:33:11.028898 140058304223104 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.08s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.09s\n",
            "I0603 04:33:11.121724 140058304223104 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.09s\n",
            "I0603 04:33:11.208929 140058304223104 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.08s\n",
            "I0603 04:33:11.292941 140058304223104 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.08s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
            "I0603 04:33:11.321150 140058304223104 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I0603 04:33:11.484624 140058304223104 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I0603 04:33:11.484762 140058304223104 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 64\n",
            "I0603 04:33:11.484831 140058304223104 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 3\n",
            "I0603 04:33:11.486821 140058304223104 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0603 04:33:11.502495 140058304223104 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0603 04:33:11.502609 140058304223104 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0603 04:33:11.557881 140058304223104 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0603 04:33:11.558012 140058304223104 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0603 04:33:11.700416 140058304223104 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0603 04:33:11.700560 140058304223104 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0603 04:33:11.853392 140058304223104 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0603 04:33:11.853608 140058304223104 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0603 04:33:12.072053 140058304223104 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0603 04:33:12.072215 140058304223104 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0603 04:33:12.441068 140058304223104 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0603 04:33:12.441234 140058304223104 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0603 04:33:12.738251 140058304223104 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0603 04:33:12.738438 140058304223104 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I0603 04:33:12.807852 140058304223104 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I0603 04:33:12.836256 140058304223104 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0603 04:33:12.882500 140058304223104 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I0603 04:33:12.882619 140058304223104 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 88\n",
            "I0603 04:33:12.882690 140058304223104 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 4\n",
            "I0603 04:33:12.884257 140058304223104 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0603 04:33:12.898070 140058304223104 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0603 04:33:12.898174 140058304223104 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0603 04:33:13.010648 140058304223104 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0603 04:33:13.010777 140058304223104 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0603 04:33:13.229110 140058304223104 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0603 04:33:13.229304 140058304223104 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0603 04:33:13.442103 140058304223104 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0603 04:33:13.442267 140058304223104 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0603 04:33:13.723370 140058304223104 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0603 04:33:13.723525 140058304223104 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0603 04:33:14.008263 140058304223104 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0603 04:33:14.008425 140058304223104 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0603 04:33:14.359633 140058304223104 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0603 04:33:14.359796 140058304223104 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I0603 04:33:14.502716 140058304223104 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I0603 04:33:14.530596 140058304223104 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0603 04:33:14.587226 140058304223104 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I0603 04:33:14.587351 140058304223104 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 112\n",
            "I0603 04:33:14.587418 140058304223104 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 5\n",
            "I0603 04:33:14.588847 140058304223104 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0603 04:33:14.602918 140058304223104 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0603 04:33:14.603048 140058304223104 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0603 04:33:14.717017 140058304223104 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0603 04:33:14.717157 140058304223104 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0603 04:33:14.938653 140058304223104 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0603 04:33:14.938805 140058304223104 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0603 04:33:15.146877 140058304223104 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0603 04:33:15.147055 140058304223104 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I0603 04:33:15.433827 140058304223104 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I0603 04:33:15.434008 140058304223104 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I0603 04:33:15.716631 140058304223104 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I0603 04:33:15.716803 140058304223104 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I0603 04:33:16.238301 140058304223104 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I0603 04:33:16.238467 140058304223104 efficientnet_model.py:143] round_filter input=320 output=352\n",
            "I0603 04:33:16.377931 140058304223104 efficientnet_model.py:143] round_filter input=1280 output=1408\n",
            "I0603 04:33:16.405153 140058304223104 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0603 04:33:16.459336 140058304223104 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I0603 04:33:16.459455 140058304223104 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 160\n",
            "I0603 04:33:16.459527 140058304223104 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 6\n",
            "I0603 04:33:16.460965 140058304223104 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I0603 04:33:16.475770 140058304223104 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I0603 04:33:16.475874 140058304223104 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0603 04:33:16.590626 140058304223104 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0603 04:33:16.590744 140058304223104 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0603 04:33:16.798492 140058304223104 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0603 04:33:16.798651 140058304223104 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0603 04:33:17.018321 140058304223104 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0603 04:33:17.018483 140058304223104 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I0603 04:33:17.378334 140058304223104 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I0603 04:33:17.378504 140058304223104 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I0603 04:33:17.733931 140058304223104 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I0603 04:33:17.734098 140058304223104 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I0603 04:33:18.164520 140058304223104 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I0603 04:33:18.164684 140058304223104 efficientnet_model.py:143] round_filter input=320 output=384\n",
            "I0603 04:33:18.303203 140058304223104 efficientnet_model.py:143] round_filter input=1280 output=1536\n",
            "I0603 04:33:18.332594 140058304223104 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0603 04:33:18.394624 140058304223104 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I0603 04:33:18.394753 140058304223104 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 224\n",
            "I0603 04:33:18.394823 140058304223104 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n",
            "I0603 04:33:18.396266 140058304223104 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0603 04:33:18.410626 140058304223104 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0603 04:33:18.410730 140058304223104 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0603 04:33:18.522241 140058304223104 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0603 04:33:18.522354 140058304223104 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0603 04:33:18.806687 140058304223104 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0603 04:33:18.806838 140058304223104 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I0603 04:33:19.108819 140058304223104 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I0603 04:33:19.108993 140058304223104 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I0603 04:33:19.533826 140058304223104 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I0603 04:33:19.534005 140058304223104 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I0603 04:33:19.964424 140058304223104 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I0603 04:33:19.964598 140058304223104 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I0603 04:33:20.533248 140058304223104 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I0603 04:33:20.533414 140058304223104 efficientnet_model.py:143] round_filter input=320 output=448\n",
            "I0603 04:33:20.908747 140058304223104 efficientnet_model.py:143] round_filter input=1280 output=1792\n",
            "I0603 04:33:20.935386 140058304223104 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0603 04:33:21.005345 140058304223104 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I0603 04:33:21.005478 140058304223104 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 288\n",
            "I0603 04:33:21.005551 140058304223104 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n",
            "I0603 04:33:21.007203 140058304223104 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0603 04:33:21.021535 140058304223104 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0603 04:33:21.021641 140058304223104 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0603 04:33:21.194588 140058304223104 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0603 04:33:21.194745 140058304223104 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0603 04:33:21.552934 140058304223104 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0603 04:33:21.553125 140058304223104 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I0603 04:33:21.914814 140058304223104 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I0603 04:33:21.915032 140058304223104 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I0603 04:33:22.414402 140058304223104 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I0603 04:33:22.414572 140058304223104 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I0603 04:33:22.911350 140058304223104 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I0603 04:33:22.911533 140058304223104 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I0603 04:33:23.556632 140058304223104 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I0603 04:33:23.556800 140058304223104 efficientnet_model.py:143] round_filter input=320 output=512\n",
            "I0603 04:33:23.771124 140058304223104 efficientnet_model.py:143] round_filter input=1280 output=2048\n",
            "I0603 04:33:23.797724 140058304223104 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0603 04:33:23.883537 140058304223104 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I0603 04:33:23.883697 140058304223104 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
            "I0603 04:33:23.883770 140058304223104 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n",
            "I0603 04:33:23.885314 140058304223104 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I0603 04:33:23.900583 140058304223104 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I0603 04:33:23.900703 140058304223104 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0603 04:33:24.080600 140058304223104 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0603 04:33:24.080776 140058304223104 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0603 04:33:24.503749 140058304223104 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0603 04:33:24.503923 140058304223104 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I0603 04:33:24.927638 140058304223104 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I0603 04:33:24.927805 140058304223104 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I0603 04:33:25.758206 140058304223104 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I0603 04:33:25.758375 140058304223104 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I0603 04:33:26.345312 140058304223104 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I0603 04:33:26.345483 140058304223104 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I0603 04:33:27.134111 140058304223104 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I0603 04:33:27.134277 140058304223104 efficientnet_model.py:143] round_filter input=320 output=576\n",
            "I0603 04:33:27.341222 140058304223104 efficientnet_model.py:143] round_filter input=1280 output=2304\n",
            "I0603 04:33:27.368238 140058304223104 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0603 04:33:27.465317 140058304223104 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I0603 04:33:27.465470 140058304223104 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
            "I0603 04:33:27.465541 140058304223104 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n",
            "I0603 04:33:27.467032 140058304223104 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I0603 04:33:27.481592 140058304223104 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I0603 04:33:27.481698 140058304223104 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0603 04:33:27.714013 140058304223104 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0603 04:33:27.714146 140058304223104 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I0603 04:33:28.210019 140058304223104 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I0603 04:33:28.210179 140058304223104 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I0603 04:33:28.711169 140058304223104 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I0603 04:33:28.711332 140058304223104 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I0603 04:33:29.436482 140058304223104 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I0603 04:33:29.436649 140058304223104 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I0603 04:33:30.153063 140058304223104 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I0603 04:33:30.153228 140058304223104 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I0603 04:33:31.339482 140058304223104 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I0603 04:33:31.339658 140058304223104 efficientnet_model.py:143] round_filter input=320 output=640\n",
            "I0603 04:33:31.617253 140058304223104 efficientnet_model.py:143] round_filter input=1280 output=2560\n",
            "I0603 04:33:31.655903 140058304223104 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 20.44s\n",
            "I0603 04:33:31.766126 140058304223104 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 20.44s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "I0603 04:33:31.772621 140058304223104 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I0603 04:33:31.774189 140058304223104 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I0603 04:33:31.774645 140058304223104 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I0603 04:33:31.776016 140058304223104 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I0603 04:33:31.777266 140058304223104 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I0603 04:33:31.777678 140058304223104 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I0603 04:33:31.778587 140058304223104 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 25.249s\n",
            "\n",
            "OK (skipped=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. CSV to TFRecord. With help from pjmam git hub\n",
        "%cd /content/gdrive/MyDrive/models/research\n",
        "!git clone https://github.com/PJMAM/project_image_processing\n",
        "!cp project_image_processing/generate_tfrecord.py .\n",
        "!cp project_image_processing/label_map.txt /content/gdrive/MyDrive/data\n",
        "\n",
        "if not os.path.exists(\"/content/gdrive/MyDrive/data/tfrecord_data/\"):\n",
        "  os.mkdir(\"/content/gdrive/MyDrive/data/tfrecord_data/\")\n",
        "\n",
        "!python generate_tfrecord.py --image_dir=/content/gdrive/MyDrive/data/split_data/train --csv_input=/content/gdrive/MyDrive/data/split_data/train_labels.csv --output_path=/content/gdrive/MyDrive/data/tfrecord_data/train.record \n",
        "!python generate_tfrecord.py --image_dir=/content/gdrive/MyDrive/data/split_data/test --csv_input=/content/gdrive/MyDrive/data/split_data/test_labels.csv --output_path=/content/gdrive/MyDrive/data/tfrecord_data/test.record \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGdAB-Tf0onr",
        "outputId": "7b5f4140-c8a7-4849-8a84-cf80ad905ae3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/models/research\n",
            "Cloning into 'project_image_processing'...\n",
            "remote: Enumerating objects: 21, done.\u001b[K\n",
            "remote: Counting objects: 100% (21/21), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 21 (delta 6), reused 21 (delta 6), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (21/21), done.\n",
            "Successfully created the TFRecords: /content/gdrive/MyDrive/data/tfrecord_data/train.record\n",
            "Successfully created the TFRecords: /content/gdrive/MyDrive/data/tfrecord_data/test.record\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Download pretrain and config\n",
        "if not os.path.exists(\"/content/gdrive/MyDrive/pretrained\"):\n",
        "  os.mkdir(\"/content/gdrive/MyDrive/pretrained\")\n",
        "\n",
        "%cd /content/gdrive/MyDrive/pretrained\n",
        "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
        "# Unzip\n",
        "!tar -xzvf ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
        "\n",
        "# Config pipeline.config, label_map.txt if needed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-b_5zgB0xzn",
        "outputId": "2b3148cc-02c2-4df7-8fda-30dbc2128aae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/pretrained\n",
            "--2022-06-03 04:33:48--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 173.194.212.128, 2607:f8b0:400c:c11::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|173.194.212.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20515344 (20M) [application/x-tar]\n",
            "Saving to: ‘ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz’\n",
            "\n",
            "ssd_mobilenet_v2_fp 100%[===================>]  19.56M  67.4MB/s    in 0.3s    \n",
            "\n",
            "2022-06-03 04:33:49 (67.4 MB/s) - ‘ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz’ saved [20515344/20515344]\n",
            "\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/checkpoint\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.index\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/saved_model.pb\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.index\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload label file object-detection.txt to data folder\n",
        "%cd /content/gdrive/MyDrive/models\n",
        "!pip install -r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt\n",
        "!pip install --upgrade opencv-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fF7RPGPl0zpv",
        "outputId": "4c850ae6-4aa0-4d95-dfeb-cb2792121766"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/models\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from -r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 1)) (2.8.0+zzzcolab20220506162203)\n",
            "Requirement already satisfied: tensorflow_io in /usr/local/lib/python3.7/dist-packages (from -r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 2)) (0.26.0)\n",
            "Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.7/dist-packages (from -r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 3)) (0.17.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from -r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 4)) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from -r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 5)) (4.2.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 6)) (3.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 7)) (1.3.5)\n",
            "Requirement already satisfied: tf_slim in /usr/local/lib/python3.7/dist-packages (from -r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 8)) (1.1.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from -r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 9)) (2.0.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from -r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 10)) (1.4.1)\n",
            "Collecting dataclasses\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from -r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 12)) (5.4.1)\n",
            "Requirement already satisfied: lvis in /usr/local/lib/python3.7/dist-packages (from -r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 13)) (0.5.3)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from -r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 14)) (0.5.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 1)) (3.19.4)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 1)) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 1)) (0.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 1)) (1.14.1)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 1)) (1.0.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 1)) (1.46.3)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 1)) (2.8.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 1)) (14.0.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 1)) (3.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 1)) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 1)) (1.21.6)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 1)) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 1)) (57.4.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 1)) (1.6.3)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 1)) (2.8.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 1)) (1.12)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 1)) (4.2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 1)) (0.26.0)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 1)) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow->-r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 1)) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->-r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 1)) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 1)) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 1)) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 1)) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 1)) (3.3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 1)) (2.27.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 1)) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 1)) (1.0.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->-r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 1)) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->-r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 1)) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->-r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 1)) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->-r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->-r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 1)) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->-r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 1)) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->-r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 1)) (0.4.8)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->-r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 1)) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->-r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 1)) (1.24.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->-r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 1)) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->-r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 1)) (2022.5.18.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->-r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 1)) (3.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons->-r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 3)) (21.3)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons->-r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 3)) (2.7.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 6)) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 6)) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 6)) (2.4.7)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 7)) (2022.1)\n",
            "Requirement already satisfied: Cython>=0.29.12 in /usr/local/lib/python3.7/dist-packages (from lvis->-r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 13)) (0.29.30)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->-r /content/gdrive/MyDrive/models/research/project_image_processing/setup.txt (line 13)) (4.1.2.30)\n",
            "Installing collected packages: dataclasses\n",
            "Successfully installed dataclasses-0.6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dataclasses"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Collecting opencv-python\n",
            "  Downloading opencv_python-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 60.5 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.21.6)\n",
            "Installing collected packages: opencv-python\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.1.2.30\n",
            "    Uninstalling opencv-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-python-4.1.2.30\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed opencv-python-4.5.5.64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "%cd /content/gdrive/MyDrive/models/research\n",
        "%cp /content/gdrive/MyDrive/models/research/object_detection/model_main_tf2.py .\n",
        "\n",
        "#train \n",
        "!python model_main_tf2.py \\\n",
        "--pipeline_config_path=/content/gdrive/MyDrive/pretrained/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config \\\n",
        "--model_dir=/content/gdrive/MyDrive/output_model --alsologtostderr --num_train_steps=10000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMsOrQvS01tJ",
        "outputId": "109326e4-964c-4249-f852-a361f5fbee45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/models/research\n",
            "2022-06-03 04:36:42.269581: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "I0603 04:36:42.275309 139663206823808 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 10000\n",
            "I0603 04:36:42.280601 139663206823808 config_util.py:552] Maybe overwriting train_steps: 10000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0603 04:36:42.280772 139663206823808 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "WARNING:tensorflow:From /content/gdrive/MyDrive/models/research/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W0603 04:36:42.424799 139663206823808 deprecation.py:343] From /content/gdrive/MyDrive/models/research/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/gdrive/MyDrive/data/tfrecord_data/train.record']\n",
            "I0603 04:36:42.436138 139663206823808 dataset_builder.py:162] Reading unweighted datasets: ['/content/gdrive/MyDrive/data/tfrecord_data/train.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/gdrive/MyDrive/data/tfrecord_data/train.record']\n",
            "I0603 04:36:42.436553 139663206823808 dataset_builder.py:79] Reading record datasets for input file: ['/content/gdrive/MyDrive/data/tfrecord_data/train.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0603 04:36:42.436679 139663206823808 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0603 04:36:42.436779 139663206823808 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /content/gdrive/MyDrive/models/research/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W0603 04:36:42.439058 139663206823808 deprecation.py:343] From /content/gdrive/MyDrive/models/research/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /content/gdrive/MyDrive/models/research/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0603 04:36:42.459231 139663206823808 deprecation.py:343] From /content/gdrive/MyDrive/models/research/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0603 04:36:49.259596 139663206823808 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0603 04:36:52.130018 139663206823808 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0603 04:36:53.747826 139663206823808 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
            "2022-06-03 04:37:27.443154: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 29500416 exceeds 10% of free system memory.\n",
            "2022-06-03 04:37:28.481135: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 29500416 exceeds 10% of free system memory.\n",
            "2022-06-03 04:37:28.489145: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 29500416 exceeds 10% of free system memory.\n",
            "2022-06-03 04:37:28.516867: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 29500416 exceeds 10% of free system memory.\n",
            "2022-06-03 04:37:28.524389: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 29500416 exceeds 10% of free system memory.\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0603 04:37:36.204403 139663206823808 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0603 04:37:36.205612 139663206823808 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0603 04:37:36.207692 139663206823808 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0603 04:37:36.208573 139663206823808 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0603 04:37:36.210596 139663206823808 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0603 04:37:36.211468 139663206823808 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0603 04:37:36.213516 139663206823808 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0603 04:37:36.214380 139663206823808 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0603 04:37:36.216381 139663206823808 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0603 04:37:36.217253 139663206823808 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:616: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "W0603 04:37:37.028455 139657965139712 deprecation.py:547] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:616: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "INFO:tensorflow:Step 100 per-step time 1.210s\n",
            "I0603 04:39:37.757879 139663206823808 model_lib_v2.py:707] Step 100 per-step time 1.210s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.77184373,\n",
            " 'Loss/localization_loss': 0.26881447,\n",
            " 'Loss/regularization_loss': 0.15336888,\n",
            " 'Loss/total_loss': 1.1940271,\n",
            " 'learning_rate': 0.0319994}\n",
            "I0603 04:39:37.758256 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.77184373,\n",
            " 'Loss/localization_loss': 0.26881447,\n",
            " 'Loss/regularization_loss': 0.15336888,\n",
            " 'Loss/total_loss': 1.1940271,\n",
            " 'learning_rate': 0.0319994}\n",
            "INFO:tensorflow:Step 200 per-step time 0.625s\n",
            "I0603 04:40:40.060187 139663206823808 model_lib_v2.py:707] Step 200 per-step time 0.625s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.35079306,\n",
            " 'Loss/localization_loss': 0.12111407,\n",
            " 'Loss/regularization_loss': 0.15324256,\n",
            " 'Loss/total_loss': 0.6251497,\n",
            " 'learning_rate': 0.0373328}\n",
            "I0603 04:40:40.060508 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.35079306,\n",
            " 'Loss/localization_loss': 0.12111407,\n",
            " 'Loss/regularization_loss': 0.15324256,\n",
            " 'Loss/total_loss': 0.6251497,\n",
            " 'learning_rate': 0.0373328}\n",
            "INFO:tensorflow:Step 300 per-step time 0.626s\n",
            "I0603 04:41:42.698001 139663206823808 model_lib_v2.py:707] Step 300 per-step time 0.626s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.2714145,\n",
            " 'Loss/localization_loss': 0.09510525,\n",
            " 'Loss/regularization_loss': 0.15298845,\n",
            " 'Loss/total_loss': 0.5195082,\n",
            " 'learning_rate': 0.0426662}\n",
            "I0603 04:41:42.698297 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.2714145,\n",
            " 'Loss/localization_loss': 0.09510525,\n",
            " 'Loss/regularization_loss': 0.15298845,\n",
            " 'Loss/total_loss': 0.5195082,\n",
            " 'learning_rate': 0.0426662}\n",
            "INFO:tensorflow:Step 400 per-step time 0.626s\n",
            "I0603 04:42:45.346716 139663206823808 model_lib_v2.py:707] Step 400 per-step time 0.626s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.19516806,\n",
            " 'Loss/localization_loss': 0.06242316,\n",
            " 'Loss/regularization_loss': 0.15267612,\n",
            " 'Loss/total_loss': 0.41026735,\n",
            " 'learning_rate': 0.047999598}\n",
            "I0603 04:42:45.347060 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.19516806,\n",
            " 'Loss/localization_loss': 0.06242316,\n",
            " 'Loss/regularization_loss': 0.15267612,\n",
            " 'Loss/total_loss': 0.41026735,\n",
            " 'learning_rate': 0.047999598}\n",
            "INFO:tensorflow:Step 500 per-step time 0.624s\n",
            "I0603 04:43:47.715119 139663206823808 model_lib_v2.py:707] Step 500 per-step time 0.624s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1396168,\n",
            " 'Loss/localization_loss': 0.047303427,\n",
            " 'Loss/regularization_loss': 0.15232337,\n",
            " 'Loss/total_loss': 0.3392436,\n",
            " 'learning_rate': 0.053333}\n",
            "I0603 04:43:47.715436 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.1396168,\n",
            " 'Loss/localization_loss': 0.047303427,\n",
            " 'Loss/regularization_loss': 0.15232337,\n",
            " 'Loss/total_loss': 0.3392436,\n",
            " 'learning_rate': 0.053333}\n",
            "INFO:tensorflow:Step 600 per-step time 0.628s\n",
            "I0603 04:44:50.524598 139663206823808 model_lib_v2.py:707] Step 600 per-step time 0.628s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1644003,\n",
            " 'Loss/localization_loss': 0.069614574,\n",
            " 'Loss/regularization_loss': 0.15194063,\n",
            " 'Loss/total_loss': 0.3859555,\n",
            " 'learning_rate': 0.0586664}\n",
            "I0603 04:44:50.524900 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.1644003,\n",
            " 'Loss/localization_loss': 0.069614574,\n",
            " 'Loss/regularization_loss': 0.15194063,\n",
            " 'Loss/total_loss': 0.3859555,\n",
            " 'learning_rate': 0.0586664}\n",
            "INFO:tensorflow:Step 700 per-step time 0.626s\n",
            "I0603 04:45:53.156274 139663206823808 model_lib_v2.py:707] Step 700 per-step time 0.626s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.14373554,\n",
            " 'Loss/localization_loss': 0.05452341,\n",
            " 'Loss/regularization_loss': 0.1514736,\n",
            " 'Loss/total_loss': 0.34973255,\n",
            " 'learning_rate': 0.0639998}\n",
            "I0603 04:45:53.156586 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.14373554,\n",
            " 'Loss/localization_loss': 0.05452341,\n",
            " 'Loss/regularization_loss': 0.1514736,\n",
            " 'Loss/total_loss': 0.34973255,\n",
            " 'learning_rate': 0.0639998}\n",
            "INFO:tensorflow:Step 800 per-step time 0.626s\n",
            "I0603 04:46:55.760018 139663206823808 model_lib_v2.py:707] Step 800 per-step time 0.626s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12416359,\n",
            " 'Loss/localization_loss': 0.041827507,\n",
            " 'Loss/regularization_loss': 0.15101889,\n",
            " 'Loss/total_loss': 0.31701,\n",
            " 'learning_rate': 0.069333196}\n",
            "I0603 04:46:55.760321 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.12416359,\n",
            " 'Loss/localization_loss': 0.041827507,\n",
            " 'Loss/regularization_loss': 0.15101889,\n",
            " 'Loss/total_loss': 0.31701,\n",
            " 'learning_rate': 0.069333196}\n",
            "INFO:tensorflow:Step 900 per-step time 0.622s\n",
            "I0603 04:47:57.964289 139663206823808 model_lib_v2.py:707] Step 900 per-step time 0.622s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.10774709,\n",
            " 'Loss/localization_loss': 0.03165548,\n",
            " 'Loss/regularization_loss': 0.15044409,\n",
            " 'Loss/total_loss': 0.28984666,\n",
            " 'learning_rate': 0.074666604}\n",
            "I0603 04:47:57.964596 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.10774709,\n",
            " 'Loss/localization_loss': 0.03165548,\n",
            " 'Loss/regularization_loss': 0.15044409,\n",
            " 'Loss/total_loss': 0.28984666,\n",
            " 'learning_rate': 0.074666604}\n",
            "INFO:tensorflow:Step 1000 per-step time 0.624s\n",
            "I0603 04:49:00.410622 139663206823808 model_lib_v2.py:707] Step 1000 per-step time 0.624s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.119729996,\n",
            " 'Loss/localization_loss': 0.03884173,\n",
            " 'Loss/regularization_loss': 0.14983232,\n",
            " 'Loss/total_loss': 0.30840403,\n",
            " 'learning_rate': 0.08}\n",
            "I0603 04:49:00.410925 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.119729996,\n",
            " 'Loss/localization_loss': 0.03884173,\n",
            " 'Loss/regularization_loss': 0.14983232,\n",
            " 'Loss/total_loss': 0.30840403,\n",
            " 'learning_rate': 0.08}\n",
            "INFO:tensorflow:Step 1100 per-step time 0.636s\n",
            "I0603 04:50:04.054465 139663206823808 model_lib_v2.py:707] Step 1100 per-step time 0.636s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09967174,\n",
            " 'Loss/localization_loss': 0.02886224,\n",
            " 'Loss/regularization_loss': 0.14928016,\n",
            " 'Loss/total_loss': 0.27781415,\n",
            " 'learning_rate': 0.07999918}\n",
            "I0603 04:50:04.054805 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.09967174,\n",
            " 'Loss/localization_loss': 0.02886224,\n",
            " 'Loss/regularization_loss': 0.14928016,\n",
            " 'Loss/total_loss': 0.27781415,\n",
            " 'learning_rate': 0.07999918}\n",
            "INFO:tensorflow:Step 1200 per-step time 0.623s\n",
            "I0603 04:51:06.388544 139663206823808 model_lib_v2.py:707] Step 1200 per-step time 0.623s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08441161,\n",
            " 'Loss/localization_loss': 0.019847948,\n",
            " 'Loss/regularization_loss': 0.14861,\n",
            " 'Loss/total_loss': 0.25286955,\n",
            " 'learning_rate': 0.079996705}\n",
            "I0603 04:51:06.388886 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.08441161,\n",
            " 'Loss/localization_loss': 0.019847948,\n",
            " 'Loss/regularization_loss': 0.14861,\n",
            " 'Loss/total_loss': 0.25286955,\n",
            " 'learning_rate': 0.079996705}\n",
            "INFO:tensorflow:Step 1300 per-step time 0.627s\n",
            "I0603 04:52:09.060131 139663206823808 model_lib_v2.py:707] Step 1300 per-step time 0.627s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.091020785,\n",
            " 'Loss/localization_loss': 0.02006476,\n",
            " 'Loss/regularization_loss': 0.1479309,\n",
            " 'Loss/total_loss': 0.25901645,\n",
            " 'learning_rate': 0.0799926}\n",
            "I0603 04:52:09.060467 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.091020785,\n",
            " 'Loss/localization_loss': 0.02006476,\n",
            " 'Loss/regularization_loss': 0.1479309,\n",
            " 'Loss/total_loss': 0.25901645,\n",
            " 'learning_rate': 0.0799926}\n",
            "INFO:tensorflow:Step 1400 per-step time 0.624s\n",
            "I0603 04:53:11.415708 139663206823808 model_lib_v2.py:707] Step 1400 per-step time 0.624s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09178937,\n",
            " 'Loss/localization_loss': 0.031988792,\n",
            " 'Loss/regularization_loss': 0.14719394,\n",
            " 'Loss/total_loss': 0.2709721,\n",
            " 'learning_rate': 0.07998685}\n",
            "I0603 04:53:11.416039 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.09178937,\n",
            " 'Loss/localization_loss': 0.031988792,\n",
            " 'Loss/regularization_loss': 0.14719394,\n",
            " 'Loss/total_loss': 0.2709721,\n",
            " 'learning_rate': 0.07998685}\n",
            "INFO:tensorflow:Step 1500 per-step time 0.625s\n",
            "I0603 04:54:13.941718 139663206823808 model_lib_v2.py:707] Step 1500 per-step time 0.625s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.076544836,\n",
            " 'Loss/localization_loss': 0.023394343,\n",
            " 'Loss/regularization_loss': 0.14648266,\n",
            " 'Loss/total_loss': 0.24642184,\n",
            " 'learning_rate': 0.07997945}\n",
            "I0603 04:54:13.942062 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.076544836,\n",
            " 'Loss/localization_loss': 0.023394343,\n",
            " 'Loss/regularization_loss': 0.14648266,\n",
            " 'Loss/total_loss': 0.24642184,\n",
            " 'learning_rate': 0.07997945}\n",
            "INFO:tensorflow:Step 1600 per-step time 0.625s\n",
            "I0603 04:55:16.430744 139663206823808 model_lib_v2.py:707] Step 1600 per-step time 0.625s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07408707,\n",
            " 'Loss/localization_loss': 0.026347956,\n",
            " 'Loss/regularization_loss': 0.14575675,\n",
            " 'Loss/total_loss': 0.24619177,\n",
            " 'learning_rate': 0.079970405}\n",
            "I0603 04:55:16.431047 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.07408707,\n",
            " 'Loss/localization_loss': 0.026347956,\n",
            " 'Loss/regularization_loss': 0.14575675,\n",
            " 'Loss/total_loss': 0.24619177,\n",
            " 'learning_rate': 0.079970405}\n",
            "INFO:tensorflow:Step 1700 per-step time 0.624s\n",
            "I0603 04:56:18.807084 139663206823808 model_lib_v2.py:707] Step 1700 per-step time 0.624s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.069871165,\n",
            " 'Loss/localization_loss': 0.013889314,\n",
            " 'Loss/regularization_loss': 0.14499943,\n",
            " 'Loss/total_loss': 0.22875991,\n",
            " 'learning_rate': 0.07995972}\n",
            "I0603 04:56:18.807405 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.069871165,\n",
            " 'Loss/localization_loss': 0.013889314,\n",
            " 'Loss/regularization_loss': 0.14499943,\n",
            " 'Loss/total_loss': 0.22875991,\n",
            " 'learning_rate': 0.07995972}\n",
            "INFO:tensorflow:Step 1800 per-step time 0.621s\n",
            "I0603 04:57:20.914298 139663206823808 model_lib_v2.py:707] Step 1800 per-step time 0.621s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09309196,\n",
            " 'Loss/localization_loss': 0.025336074,\n",
            " 'Loss/regularization_loss': 0.1442289,\n",
            " 'Loss/total_loss': 0.26265693,\n",
            " 'learning_rate': 0.0799474}\n",
            "I0603 04:57:20.914587 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.09309196,\n",
            " 'Loss/localization_loss': 0.025336074,\n",
            " 'Loss/regularization_loss': 0.1442289,\n",
            " 'Loss/total_loss': 0.26265693,\n",
            " 'learning_rate': 0.0799474}\n",
            "INFO:tensorflow:Step 1900 per-step time 0.621s\n",
            "I0603 04:58:23.037081 139663206823808 model_lib_v2.py:707] Step 1900 per-step time 0.621s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05762528,\n",
            " 'Loss/localization_loss': 0.017754097,\n",
            " 'Loss/regularization_loss': 0.14345779,\n",
            " 'Loss/total_loss': 0.21883716,\n",
            " 'learning_rate': 0.07993342}\n",
            "I0603 04:58:23.037393 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.05762528,\n",
            " 'Loss/localization_loss': 0.017754097,\n",
            " 'Loss/regularization_loss': 0.14345779,\n",
            " 'Loss/total_loss': 0.21883716,\n",
            " 'learning_rate': 0.07993342}\n",
            "INFO:tensorflow:Step 2000 per-step time 0.620s\n",
            "I0603 04:59:25.002763 139663206823808 model_lib_v2.py:707] Step 2000 per-step time 0.620s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07332284,\n",
            " 'Loss/localization_loss': 0.023596076,\n",
            " 'Loss/regularization_loss': 0.1426909,\n",
            " 'Loss/total_loss': 0.23960981,\n",
            " 'learning_rate': 0.07991781}\n",
            "I0603 04:59:25.003062 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.07332284,\n",
            " 'Loss/localization_loss': 0.023596076,\n",
            " 'Loss/regularization_loss': 0.1426909,\n",
            " 'Loss/total_loss': 0.23960981,\n",
            " 'learning_rate': 0.07991781}\n",
            "INFO:tensorflow:Step 2100 per-step time 0.627s\n",
            "I0603 05:00:27.660139 139663206823808 model_lib_v2.py:707] Step 2100 per-step time 0.627s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07153763,\n",
            " 'Loss/localization_loss': 0.029774029,\n",
            " 'Loss/regularization_loss': 0.14197467,\n",
            " 'Loss/total_loss': 0.24328633,\n",
            " 'learning_rate': 0.07990056}\n",
            "I0603 05:00:27.660462 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.07153763,\n",
            " 'Loss/localization_loss': 0.029774029,\n",
            " 'Loss/regularization_loss': 0.14197467,\n",
            " 'Loss/total_loss': 0.24328633,\n",
            " 'learning_rate': 0.07990056}\n",
            "INFO:tensorflow:Step 2200 per-step time 0.622s\n",
            "I0603 05:01:29.899651 139663206823808 model_lib_v2.py:707] Step 2200 per-step time 0.622s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.075170696,\n",
            " 'Loss/localization_loss': 0.021650342,\n",
            " 'Loss/regularization_loss': 0.1412246,\n",
            " 'Loss/total_loss': 0.23804563,\n",
            " 'learning_rate': 0.07988167}\n",
            "I0603 05:01:29.899937 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.075170696,\n",
            " 'Loss/localization_loss': 0.021650342,\n",
            " 'Loss/regularization_loss': 0.1412246,\n",
            " 'Loss/total_loss': 0.23804563,\n",
            " 'learning_rate': 0.07988167}\n",
            "INFO:tensorflow:Step 2300 per-step time 0.625s\n",
            "I0603 05:02:32.427114 139663206823808 model_lib_v2.py:707] Step 2300 per-step time 0.625s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.074229434,\n",
            " 'Loss/localization_loss': 0.016661337,\n",
            " 'Loss/regularization_loss': 0.14046162,\n",
            " 'Loss/total_loss': 0.23135239,\n",
            " 'learning_rate': 0.07986114}\n",
            "I0603 05:02:32.427429 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.074229434,\n",
            " 'Loss/localization_loss': 0.016661337,\n",
            " 'Loss/regularization_loss': 0.14046162,\n",
            " 'Loss/total_loss': 0.23135239,\n",
            " 'learning_rate': 0.07986114}\n",
            "INFO:tensorflow:Step 2400 per-step time 0.621s\n",
            "I0603 05:03:34.524922 139663206823808 model_lib_v2.py:707] Step 2400 per-step time 0.621s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.057093665,\n",
            " 'Loss/localization_loss': 0.018180162,\n",
            " 'Loss/regularization_loss': 0.13972712,\n",
            " 'Loss/total_loss': 0.21500094,\n",
            " 'learning_rate': 0.07983897}\n",
            "I0603 05:03:34.525233 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.057093665,\n",
            " 'Loss/localization_loss': 0.018180162,\n",
            " 'Loss/regularization_loss': 0.13972712,\n",
            " 'Loss/total_loss': 0.21500094,\n",
            " 'learning_rate': 0.07983897}\n",
            "INFO:tensorflow:Step 2500 per-step time 0.626s\n",
            "I0603 05:04:37.099700 139663206823808 model_lib_v2.py:707] Step 2500 per-step time 0.626s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06410966,\n",
            " 'Loss/localization_loss': 0.015442358,\n",
            " 'Loss/regularization_loss': 0.13897777,\n",
            " 'Loss/total_loss': 0.21852979,\n",
            " 'learning_rate': 0.079815164}\n",
            "I0603 05:04:37.100021 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.06410966,\n",
            " 'Loss/localization_loss': 0.015442358,\n",
            " 'Loss/regularization_loss': 0.13897777,\n",
            " 'Loss/total_loss': 0.21852979,\n",
            " 'learning_rate': 0.079815164}\n",
            "INFO:tensorflow:Step 2600 per-step time 0.619s\n",
            "I0603 05:05:39.048261 139663206823808 model_lib_v2.py:707] Step 2600 per-step time 0.619s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05679742,\n",
            " 'Loss/localization_loss': 0.016612526,\n",
            " 'Loss/regularization_loss': 0.13828874,\n",
            " 'Loss/total_loss': 0.21169868,\n",
            " 'learning_rate': 0.07978972}\n",
            "I0603 05:05:39.048558 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.05679742,\n",
            " 'Loss/localization_loss': 0.016612526,\n",
            " 'Loss/regularization_loss': 0.13828874,\n",
            " 'Loss/total_loss': 0.21169868,\n",
            " 'learning_rate': 0.07978972}\n",
            "INFO:tensorflow:Step 2700 per-step time 0.623s\n",
            "I0603 05:06:41.309248 139663206823808 model_lib_v2.py:707] Step 2700 per-step time 0.623s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.057197485,\n",
            " 'Loss/localization_loss': 0.017117428,\n",
            " 'Loss/regularization_loss': 0.13754953,\n",
            " 'Loss/total_loss': 0.21186444,\n",
            " 'learning_rate': 0.07976264}\n",
            "I0603 05:06:41.309568 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.057197485,\n",
            " 'Loss/localization_loss': 0.017117428,\n",
            " 'Loss/regularization_loss': 0.13754953,\n",
            " 'Loss/total_loss': 0.21186444,\n",
            " 'learning_rate': 0.07976264}\n",
            "INFO:tensorflow:Step 2800 per-step time 0.624s\n",
            "I0603 05:07:43.718385 139663206823808 model_lib_v2.py:707] Step 2800 per-step time 0.624s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.070730366,\n",
            " 'Loss/localization_loss': 0.021376206,\n",
            " 'Loss/regularization_loss': 0.13680504,\n",
            " 'Loss/total_loss': 0.22891161,\n",
            " 'learning_rate': 0.07973392}\n",
            "I0603 05:07:43.718709 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.070730366,\n",
            " 'Loss/localization_loss': 0.021376206,\n",
            " 'Loss/regularization_loss': 0.13680504,\n",
            " 'Loss/total_loss': 0.22891161,\n",
            " 'learning_rate': 0.07973392}\n",
            "INFO:tensorflow:Step 2900 per-step time 0.623s\n",
            "I0603 05:08:46.020041 139663206823808 model_lib_v2.py:707] Step 2900 per-step time 0.623s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.055551387,\n",
            " 'Loss/localization_loss': 0.011517463,\n",
            " 'Loss/regularization_loss': 0.13606963,\n",
            " 'Loss/total_loss': 0.20313847,\n",
            " 'learning_rate': 0.07970358}\n",
            "I0603 05:08:46.020337 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.055551387,\n",
            " 'Loss/localization_loss': 0.011517463,\n",
            " 'Loss/regularization_loss': 0.13606963,\n",
            " 'Loss/total_loss': 0.20313847,\n",
            " 'learning_rate': 0.07970358}\n",
            "INFO:tensorflow:Step 3000 per-step time 0.626s\n",
            "I0603 05:09:48.609932 139663206823808 model_lib_v2.py:707] Step 3000 per-step time 0.626s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07374898,\n",
            " 'Loss/localization_loss': 0.016703878,\n",
            " 'Loss/regularization_loss': 0.13588819,\n",
            " 'Loss/total_loss': 0.22634105,\n",
            " 'learning_rate': 0.0796716}\n",
            "I0603 05:09:48.610259 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.07374898,\n",
            " 'Loss/localization_loss': 0.016703878,\n",
            " 'Loss/regularization_loss': 0.13588819,\n",
            " 'Loss/total_loss': 0.22634105,\n",
            " 'learning_rate': 0.0796716}\n",
            "INFO:tensorflow:Step 3100 per-step time 0.628s\n",
            "I0603 05:10:51.410527 139663206823808 model_lib_v2.py:707] Step 3100 per-step time 0.628s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08904191,\n",
            " 'Loss/localization_loss': 0.02907404,\n",
            " 'Loss/regularization_loss': 0.13575184,\n",
            " 'Loss/total_loss': 0.2538678,\n",
            " 'learning_rate': 0.07963799}\n",
            "I0603 05:10:51.410832 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.08904191,\n",
            " 'Loss/localization_loss': 0.02907404,\n",
            " 'Loss/regularization_loss': 0.13575184,\n",
            " 'Loss/total_loss': 0.2538678,\n",
            " 'learning_rate': 0.07963799}\n",
            "INFO:tensorflow:Step 3200 per-step time 0.625s\n",
            "I0603 05:11:53.871541 139663206823808 model_lib_v2.py:707] Step 3200 per-step time 0.625s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.058445036,\n",
            " 'Loss/localization_loss': 0.012934034,\n",
            " 'Loss/regularization_loss': 0.1353453,\n",
            " 'Loss/total_loss': 0.20672438,\n",
            " 'learning_rate': 0.07960275}\n",
            "I0603 05:11:53.871850 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.058445036,\n",
            " 'Loss/localization_loss': 0.012934034,\n",
            " 'Loss/regularization_loss': 0.1353453,\n",
            " 'Loss/total_loss': 0.20672438,\n",
            " 'learning_rate': 0.07960275}\n",
            "INFO:tensorflow:Step 3300 per-step time 0.624s\n",
            "I0603 05:12:56.225944 139663206823808 model_lib_v2.py:707] Step 3300 per-step time 0.624s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05473229,\n",
            " 'Loss/localization_loss': 0.01645705,\n",
            " 'Loss/regularization_loss': 0.13462941,\n",
            " 'Loss/total_loss': 0.20581874,\n",
            " 'learning_rate': 0.07956588}\n",
            "I0603 05:12:56.226252 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.05473229,\n",
            " 'Loss/localization_loss': 0.01645705,\n",
            " 'Loss/regularization_loss': 0.13462941,\n",
            " 'Loss/total_loss': 0.20581874,\n",
            " 'learning_rate': 0.07956588}\n",
            "INFO:tensorflow:Step 3400 per-step time 0.625s\n",
            "I0603 05:13:58.697825 139663206823808 model_lib_v2.py:707] Step 3400 per-step time 0.625s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.04974168,\n",
            " 'Loss/localization_loss': 0.012910035,\n",
            " 'Loss/regularization_loss': 0.13389556,\n",
            " 'Loss/total_loss': 0.19654727,\n",
            " 'learning_rate': 0.079527386}\n",
            "I0603 05:13:58.698140 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.04974168,\n",
            " 'Loss/localization_loss': 0.012910035,\n",
            " 'Loss/regularization_loss': 0.13389556,\n",
            " 'Loss/total_loss': 0.19654727,\n",
            " 'learning_rate': 0.079527386}\n",
            "INFO:tensorflow:Step 3500 per-step time 0.623s\n",
            "I0603 05:15:01.006718 139663206823808 model_lib_v2.py:707] Step 3500 per-step time 0.623s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.045512352,\n",
            " 'Loss/localization_loss': 0.0134708155,\n",
            " 'Loss/regularization_loss': 0.13315275,\n",
            " 'Loss/total_loss': 0.19213593,\n",
            " 'learning_rate': 0.07948727}\n",
            "I0603 05:15:01.007029 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.045512352,\n",
            " 'Loss/localization_loss': 0.0134708155,\n",
            " 'Loss/regularization_loss': 0.13315275,\n",
            " 'Loss/total_loss': 0.19213593,\n",
            " 'learning_rate': 0.07948727}\n",
            "INFO:tensorflow:Step 3600 per-step time 0.626s\n",
            "I0603 05:16:03.569633 139663206823808 model_lib_v2.py:707] Step 3600 per-step time 0.626s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.050303973,\n",
            " 'Loss/localization_loss': 0.013118024,\n",
            " 'Loss/regularization_loss': 0.13241172,\n",
            " 'Loss/total_loss': 0.19583371,\n",
            " 'learning_rate': 0.079445526}\n",
            "I0603 05:16:03.569940 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.050303973,\n",
            " 'Loss/localization_loss': 0.013118024,\n",
            " 'Loss/regularization_loss': 0.13241172,\n",
            " 'Loss/total_loss': 0.19583371,\n",
            " 'learning_rate': 0.079445526}\n",
            "INFO:tensorflow:Step 3700 per-step time 0.625s\n",
            "I0603 05:17:06.084458 139663206823808 model_lib_v2.py:707] Step 3700 per-step time 0.625s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.055214632,\n",
            " 'Loss/localization_loss': 0.019274563,\n",
            " 'Loss/regularization_loss': 0.13166457,\n",
            " 'Loss/total_loss': 0.20615377,\n",
            " 'learning_rate': 0.07940216}\n",
            "I0603 05:17:06.084752 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.055214632,\n",
            " 'Loss/localization_loss': 0.019274563,\n",
            " 'Loss/regularization_loss': 0.13166457,\n",
            " 'Loss/total_loss': 0.20615377,\n",
            " 'learning_rate': 0.07940216}\n",
            "INFO:tensorflow:Step 3800 per-step time 0.625s\n",
            "I0603 05:18:08.609708 139663206823808 model_lib_v2.py:707] Step 3800 per-step time 0.625s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.04969844,\n",
            " 'Loss/localization_loss': 0.010902218,\n",
            " 'Loss/regularization_loss': 0.13096195,\n",
            " 'Loss/total_loss': 0.19156261,\n",
            " 'learning_rate': 0.079357184}\n",
            "I0603 05:18:08.610080 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.04969844,\n",
            " 'Loss/localization_loss': 0.010902218,\n",
            " 'Loss/regularization_loss': 0.13096195,\n",
            " 'Loss/total_loss': 0.19156261,\n",
            " 'learning_rate': 0.079357184}\n",
            "INFO:tensorflow:Step 3900 per-step time 0.623s\n",
            "I0603 05:19:10.932790 139663206823808 model_lib_v2.py:707] Step 3900 per-step time 0.623s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.047251638,\n",
            " 'Loss/localization_loss': 0.010198061,\n",
            " 'Loss/regularization_loss': 0.13027617,\n",
            " 'Loss/total_loss': 0.18772587,\n",
            " 'learning_rate': 0.07931058}\n",
            "I0603 05:19:10.933096 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.047251638,\n",
            " 'Loss/localization_loss': 0.010198061,\n",
            " 'Loss/regularization_loss': 0.13027617,\n",
            " 'Loss/total_loss': 0.18772587,\n",
            " 'learning_rate': 0.07931058}\n",
            "INFO:tensorflow:Step 4000 per-step time 0.625s\n",
            "I0603 05:20:13.424771 139663206823808 model_lib_v2.py:707] Step 4000 per-step time 0.625s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.057534758,\n",
            " 'Loss/localization_loss': 0.011780509,\n",
            " 'Loss/regularization_loss': 0.12956321,\n",
            " 'Loss/total_loss': 0.19887848,\n",
            " 'learning_rate': 0.07926236}\n",
            "I0603 05:20:13.425144 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.057534758,\n",
            " 'Loss/localization_loss': 0.011780509,\n",
            " 'Loss/regularization_loss': 0.12956321,\n",
            " 'Loss/total_loss': 0.19887848,\n",
            " 'learning_rate': 0.07926236}\n",
            "INFO:tensorflow:Step 4100 per-step time 0.626s\n",
            "I0603 05:21:15.987078 139663206823808 model_lib_v2.py:707] Step 4100 per-step time 0.626s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.047887504,\n",
            " 'Loss/localization_loss': 0.010813313,\n",
            " 'Loss/regularization_loss': 0.12886053,\n",
            " 'Loss/total_loss': 0.18756135,\n",
            " 'learning_rate': 0.07921253}\n",
            "I0603 05:21:15.987379 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.047887504,\n",
            " 'Loss/localization_loss': 0.010813313,\n",
            " 'Loss/regularization_loss': 0.12886053,\n",
            " 'Loss/total_loss': 0.18756135,\n",
            " 'learning_rate': 0.07921253}\n",
            "INFO:tensorflow:Step 4200 per-step time 0.623s\n",
            "I0603 05:22:18.253290 139663206823808 model_lib_v2.py:707] Step 4200 per-step time 0.623s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.047554262,\n",
            " 'Loss/localization_loss': 0.00900709,\n",
            " 'Loss/regularization_loss': 0.12814906,\n",
            " 'Loss/total_loss': 0.18471041,\n",
            " 'learning_rate': 0.07916109}\n",
            "I0603 05:22:18.253598 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.047554262,\n",
            " 'Loss/localization_loss': 0.00900709,\n",
            " 'Loss/regularization_loss': 0.12814906,\n",
            " 'Loss/total_loss': 0.18471041,\n",
            " 'learning_rate': 0.07916109}\n",
            "INFO:tensorflow:Step 4300 per-step time 0.626s\n",
            "I0603 05:23:20.816011 139663206823808 model_lib_v2.py:707] Step 4300 per-step time 0.626s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.037270863,\n",
            " 'Loss/localization_loss': 0.007846557,\n",
            " 'Loss/regularization_loss': 0.12743,\n",
            " 'Loss/total_loss': 0.17254743,\n",
            " 'learning_rate': 0.07910804}\n",
            "I0603 05:23:20.816296 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.037270863,\n",
            " 'Loss/localization_loss': 0.007846557,\n",
            " 'Loss/regularization_loss': 0.12743,\n",
            " 'Loss/total_loss': 0.17254743,\n",
            " 'learning_rate': 0.07910804}\n",
            "INFO:tensorflow:Step 4400 per-step time 0.620s\n",
            "I0603 05:24:22.809172 139663206823808 model_lib_v2.py:707] Step 4400 per-step time 0.620s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.043073136,\n",
            " 'Loss/localization_loss': 0.012457057,\n",
            " 'Loss/regularization_loss': 0.12671493,\n",
            " 'Loss/total_loss': 0.18224512,\n",
            " 'learning_rate': 0.07905338}\n",
            "I0603 05:24:22.809469 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.043073136,\n",
            " 'Loss/localization_loss': 0.012457057,\n",
            " 'Loss/regularization_loss': 0.12671493,\n",
            " 'Loss/total_loss': 0.18224512,\n",
            " 'learning_rate': 0.07905338}\n",
            "INFO:tensorflow:Step 4500 per-step time 0.623s\n",
            "I0603 05:25:25.078253 139663206823808 model_lib_v2.py:707] Step 4500 per-step time 0.623s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.055079058,\n",
            " 'Loss/localization_loss': 0.022538358,\n",
            " 'Loss/regularization_loss': 0.12601037,\n",
            " 'Loss/total_loss': 0.2036278,\n",
            " 'learning_rate': 0.07899711}\n",
            "I0603 05:25:25.078536 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.055079058,\n",
            " 'Loss/localization_loss': 0.022538358,\n",
            " 'Loss/regularization_loss': 0.12601037,\n",
            " 'Loss/total_loss': 0.2036278,\n",
            " 'learning_rate': 0.07899711}\n",
            "INFO:tensorflow:Step 4600 per-step time 0.624s\n",
            "I0603 05:26:27.472999 139663206823808 model_lib_v2.py:707] Step 4600 per-step time 0.624s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.040513344,\n",
            " 'Loss/localization_loss': 0.011386738,\n",
            " 'Loss/regularization_loss': 0.12531173,\n",
            " 'Loss/total_loss': 0.17721182,\n",
            " 'learning_rate': 0.078939244}\n",
            "I0603 05:26:27.473308 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.040513344,\n",
            " 'Loss/localization_loss': 0.011386738,\n",
            " 'Loss/regularization_loss': 0.12531173,\n",
            " 'Loss/total_loss': 0.17721182,\n",
            " 'learning_rate': 0.078939244}\n",
            "INFO:tensorflow:Step 4700 per-step time 0.623s\n",
            "I0603 05:27:29.816242 139663206823808 model_lib_v2.py:707] Step 4700 per-step time 0.623s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.04502739,\n",
            " 'Loss/localization_loss': 0.008608119,\n",
            " 'Loss/regularization_loss': 0.12461617,\n",
            " 'Loss/total_loss': 0.17825168,\n",
            " 'learning_rate': 0.07887978}\n",
            "I0603 05:27:29.816529 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.04502739,\n",
            " 'Loss/localization_loss': 0.008608119,\n",
            " 'Loss/regularization_loss': 0.12461617,\n",
            " 'Loss/total_loss': 0.17825168,\n",
            " 'learning_rate': 0.07887978}\n",
            "INFO:tensorflow:Step 4800 per-step time 0.624s\n",
            "I0603 05:28:32.175829 139663206823808 model_lib_v2.py:707] Step 4800 per-step time 0.624s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.048144195,\n",
            " 'Loss/localization_loss': 0.012030752,\n",
            " 'Loss/regularization_loss': 0.123917066,\n",
            " 'Loss/total_loss': 0.18409202,\n",
            " 'learning_rate': 0.07881871}\n",
            "I0603 05:28:32.176150 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.048144195,\n",
            " 'Loss/localization_loss': 0.012030752,\n",
            " 'Loss/regularization_loss': 0.123917066,\n",
            " 'Loss/total_loss': 0.18409202,\n",
            " 'learning_rate': 0.07881871}\n",
            "INFO:tensorflow:Step 4900 per-step time 0.621s\n",
            "I0603 05:29:34.275919 139663206823808 model_lib_v2.py:707] Step 4900 per-step time 0.621s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.043448795,\n",
            " 'Loss/localization_loss': 0.013336836,\n",
            " 'Loss/regularization_loss': 0.12323472,\n",
            " 'Loss/total_loss': 0.18002035,\n",
            " 'learning_rate': 0.07875605}\n",
            "I0603 05:29:34.276224 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.043448795,\n",
            " 'Loss/localization_loss': 0.013336836,\n",
            " 'Loss/regularization_loss': 0.12323472,\n",
            " 'Loss/total_loss': 0.18002035,\n",
            " 'learning_rate': 0.07875605}\n",
            "INFO:tensorflow:Step 5000 per-step time 0.622s\n",
            "I0603 05:30:36.523589 139663206823808 model_lib_v2.py:707] Step 5000 per-step time 0.622s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.034155536,\n",
            " 'Loss/localization_loss': 0.0057665915,\n",
            " 'Loss/regularization_loss': 0.122548826,\n",
            " 'Loss/total_loss': 0.16247095,\n",
            " 'learning_rate': 0.078691795}\n",
            "I0603 05:30:36.523891 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.034155536,\n",
            " 'Loss/localization_loss': 0.0057665915,\n",
            " 'Loss/regularization_loss': 0.122548826,\n",
            " 'Loss/total_loss': 0.16247095,\n",
            " 'learning_rate': 0.078691795}\n",
            "INFO:tensorflow:Step 5100 per-step time 0.632s\n",
            "I0603 05:31:39.716085 139663206823808 model_lib_v2.py:707] Step 5100 per-step time 0.632s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.03439855,\n",
            " 'Loss/localization_loss': 0.0063854447,\n",
            " 'Loss/regularization_loss': 0.12186461,\n",
            " 'Loss/total_loss': 0.1626486,\n",
            " 'learning_rate': 0.07862595}\n",
            "I0603 05:31:39.716393 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.03439855,\n",
            " 'Loss/localization_loss': 0.0063854447,\n",
            " 'Loss/regularization_loss': 0.12186461,\n",
            " 'Loss/total_loss': 0.1626486,\n",
            " 'learning_rate': 0.07862595}\n",
            "INFO:tensorflow:Step 5200 per-step time 0.622s\n",
            "I0603 05:32:41.924603 139663206823808 model_lib_v2.py:707] Step 5200 per-step time 0.622s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.035790656,\n",
            " 'Loss/localization_loss': 0.007159113,\n",
            " 'Loss/regularization_loss': 0.12119012,\n",
            " 'Loss/total_loss': 0.1641399,\n",
            " 'learning_rate': 0.07855851}\n",
            "I0603 05:32:41.924901 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.035790656,\n",
            " 'Loss/localization_loss': 0.007159113,\n",
            " 'Loss/regularization_loss': 0.12119012,\n",
            " 'Loss/total_loss': 0.1641399,\n",
            " 'learning_rate': 0.07855851}\n",
            "INFO:tensorflow:Step 5300 per-step time 0.622s\n",
            "I0603 05:33:44.095386 139663206823808 model_lib_v2.py:707] Step 5300 per-step time 0.622s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.044815026,\n",
            " 'Loss/localization_loss': 0.01632953,\n",
            " 'Loss/regularization_loss': 0.120518416,\n",
            " 'Loss/total_loss': 0.18166298,\n",
            " 'learning_rate': 0.07848949}\n",
            "I0603 05:33:44.095685 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.044815026,\n",
            " 'Loss/localization_loss': 0.01632953,\n",
            " 'Loss/regularization_loss': 0.120518416,\n",
            " 'Loss/total_loss': 0.18166298,\n",
            " 'learning_rate': 0.07848949}\n",
            "INFO:tensorflow:Step 5400 per-step time 0.624s\n",
            "I0603 05:34:46.455390 139663206823808 model_lib_v2.py:707] Step 5400 per-step time 0.624s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.047365442,\n",
            " 'Loss/localization_loss': 0.011613432,\n",
            " 'Loss/regularization_loss': 0.119855106,\n",
            " 'Loss/total_loss': 0.17883398,\n",
            " 'learning_rate': 0.078418896}\n",
            "I0603 05:34:46.455694 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.047365442,\n",
            " 'Loss/localization_loss': 0.011613432,\n",
            " 'Loss/regularization_loss': 0.119855106,\n",
            " 'Loss/total_loss': 0.17883398,\n",
            " 'learning_rate': 0.078418896}\n",
            "INFO:tensorflow:Step 5500 per-step time 0.624s\n",
            "I0603 05:35:48.867074 139663206823808 model_lib_v2.py:707] Step 5500 per-step time 0.624s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.038224794,\n",
            " 'Loss/localization_loss': 0.009695892,\n",
            " 'Loss/regularization_loss': 0.11920114,\n",
            " 'Loss/total_loss': 0.16712183,\n",
            " 'learning_rate': 0.078346714}\n",
            "I0603 05:35:48.867372 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.038224794,\n",
            " 'Loss/localization_loss': 0.009695892,\n",
            " 'Loss/regularization_loss': 0.11920114,\n",
            " 'Loss/total_loss': 0.16712183,\n",
            " 'learning_rate': 0.078346714}\n",
            "INFO:tensorflow:Step 5600 per-step time 0.626s\n",
            "I0603 05:36:51.466660 139663206823808 model_lib_v2.py:707] Step 5600 per-step time 0.626s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.041190956,\n",
            " 'Loss/localization_loss': 0.006863958,\n",
            " 'Loss/regularization_loss': 0.1185385,\n",
            " 'Loss/total_loss': 0.16659342,\n",
            " 'learning_rate': 0.07827295}\n",
            "I0603 05:36:51.466941 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.041190956,\n",
            " 'Loss/localization_loss': 0.006863958,\n",
            " 'Loss/regularization_loss': 0.1185385,\n",
            " 'Loss/total_loss': 0.16659342,\n",
            " 'learning_rate': 0.07827295}\n",
            "INFO:tensorflow:Step 5700 per-step time 0.622s\n",
            "I0603 05:37:53.629395 139663206823808 model_lib_v2.py:707] Step 5700 per-step time 0.622s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.03682513,\n",
            " 'Loss/localization_loss': 0.010745917,\n",
            " 'Loss/regularization_loss': 0.11788363,\n",
            " 'Loss/total_loss': 0.16545469,\n",
            " 'learning_rate': 0.07819763}\n",
            "I0603 05:37:53.629697 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.03682513,\n",
            " 'Loss/localization_loss': 0.010745917,\n",
            " 'Loss/regularization_loss': 0.11788363,\n",
            " 'Loss/total_loss': 0.16545469,\n",
            " 'learning_rate': 0.07819763}\n",
            "INFO:tensorflow:Step 5800 per-step time 0.623s\n",
            "I0603 05:38:55.975559 139663206823808 model_lib_v2.py:707] Step 5800 per-step time 0.623s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.046968002,\n",
            " 'Loss/localization_loss': 0.011888835,\n",
            " 'Loss/regularization_loss': 0.11722979,\n",
            " 'Loss/total_loss': 0.17608663,\n",
            " 'learning_rate': 0.07812072}\n",
            "I0603 05:38:55.975862 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.046968002,\n",
            " 'Loss/localization_loss': 0.011888835,\n",
            " 'Loss/regularization_loss': 0.11722979,\n",
            " 'Loss/total_loss': 0.17608663,\n",
            " 'learning_rate': 0.07812072}\n",
            "INFO:tensorflow:Step 5900 per-step time 0.624s\n",
            "I0603 05:39:58.327915 139663206823808 model_lib_v2.py:707] Step 5900 per-step time 0.624s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.048512023,\n",
            " 'Loss/localization_loss': 0.008495516,\n",
            " 'Loss/regularization_loss': 0.11659532,\n",
            " 'Loss/total_loss': 0.17360286,\n",
            " 'learning_rate': 0.078042254}\n",
            "I0603 05:39:58.328229 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.048512023,\n",
            " 'Loss/localization_loss': 0.008495516,\n",
            " 'Loss/regularization_loss': 0.11659532,\n",
            " 'Loss/total_loss': 0.17360286,\n",
            " 'learning_rate': 0.078042254}\n",
            "INFO:tensorflow:Step 6000 per-step time 0.623s\n",
            "I0603 05:41:00.585390 139663206823808 model_lib_v2.py:707] Step 6000 per-step time 0.623s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.03377908,\n",
            " 'Loss/localization_loss': 0.00896069,\n",
            " 'Loss/regularization_loss': 0.11595153,\n",
            " 'Loss/total_loss': 0.1586913,\n",
            " 'learning_rate': 0.07796223}\n",
            "I0603 05:41:00.585677 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.03377908,\n",
            " 'Loss/localization_loss': 0.00896069,\n",
            " 'Loss/regularization_loss': 0.11595153,\n",
            " 'Loss/total_loss': 0.1586913,\n",
            " 'learning_rate': 0.07796223}\n",
            "INFO:tensorflow:Step 6100 per-step time 0.627s\n",
            "I0603 05:42:03.239889 139663206823808 model_lib_v2.py:707] Step 6100 per-step time 0.627s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.04040929,\n",
            " 'Loss/localization_loss': 0.01466045,\n",
            " 'Loss/regularization_loss': 0.11530899,\n",
            " 'Loss/total_loss': 0.17037873,\n",
            " 'learning_rate': 0.077880636}\n",
            "I0603 05:42:03.240205 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.04040929,\n",
            " 'Loss/localization_loss': 0.01466045,\n",
            " 'Loss/regularization_loss': 0.11530899,\n",
            " 'Loss/total_loss': 0.17037873,\n",
            " 'learning_rate': 0.077880636}\n",
            "INFO:tensorflow:Step 6200 per-step time 0.622s\n",
            "I0603 05:43:05.483308 139663206823808 model_lib_v2.py:707] Step 6200 per-step time 0.622s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.039155617,\n",
            " 'Loss/localization_loss': 0.009448641,\n",
            " 'Loss/regularization_loss': 0.114693865,\n",
            " 'Loss/total_loss': 0.16329813,\n",
            " 'learning_rate': 0.07779749}\n",
            "I0603 05:43:05.483585 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.039155617,\n",
            " 'Loss/localization_loss': 0.009448641,\n",
            " 'Loss/regularization_loss': 0.114693865,\n",
            " 'Loss/total_loss': 0.16329813,\n",
            " 'learning_rate': 0.07779749}\n",
            "INFO:tensorflow:Step 6300 per-step time 0.622s\n",
            "I0603 05:44:07.638624 139663206823808 model_lib_v2.py:707] Step 6300 per-step time 0.622s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.029409517,\n",
            " 'Loss/localization_loss': 0.010293002,\n",
            " 'Loss/regularization_loss': 0.11407303,\n",
            " 'Loss/total_loss': 0.15377554,\n",
            " 'learning_rate': 0.07771279}\n",
            "I0603 05:44:07.639000 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.029409517,\n",
            " 'Loss/localization_loss': 0.010293002,\n",
            " 'Loss/regularization_loss': 0.11407303,\n",
            " 'Loss/total_loss': 0.15377554,\n",
            " 'learning_rate': 0.07771279}\n",
            "INFO:tensorflow:Step 6400 per-step time 0.619s\n",
            "I0603 05:45:09.586437 139663206823808 model_lib_v2.py:707] Step 6400 per-step time 0.619s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.04089197,\n",
            " 'Loss/localization_loss': 0.010904587,\n",
            " 'Loss/regularization_loss': 0.11344943,\n",
            " 'Loss/total_loss': 0.165246,\n",
            " 'learning_rate': 0.077626534}\n",
            "I0603 05:45:09.586755 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.04089197,\n",
            " 'Loss/localization_loss': 0.010904587,\n",
            " 'Loss/regularization_loss': 0.11344943,\n",
            " 'Loss/total_loss': 0.165246,\n",
            " 'learning_rate': 0.077626534}\n",
            "INFO:tensorflow:Step 6500 per-step time 0.620s\n",
            "I0603 05:46:11.626116 139663206823808 model_lib_v2.py:707] Step 6500 per-step time 0.620s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.04464712,\n",
            " 'Loss/localization_loss': 0.010182113,\n",
            " 'Loss/regularization_loss': 0.11315196,\n",
            " 'Loss/total_loss': 0.16798119,\n",
            " 'learning_rate': 0.077538736}\n",
            "I0603 05:46:11.626432 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.04464712,\n",
            " 'Loss/localization_loss': 0.010182113,\n",
            " 'Loss/regularization_loss': 0.11315196,\n",
            " 'Loss/total_loss': 0.16798119,\n",
            " 'learning_rate': 0.077538736}\n",
            "INFO:tensorflow:Step 6600 per-step time 0.621s\n",
            "I0603 05:47:13.751594 139663206823808 model_lib_v2.py:707] Step 6600 per-step time 0.621s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.04873983,\n",
            " 'Loss/localization_loss': 0.01468087,\n",
            " 'Loss/regularization_loss': 0.1127992,\n",
            " 'Loss/total_loss': 0.1762199,\n",
            " 'learning_rate': 0.077449396}\n",
            "I0603 05:47:13.751867 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.04873983,\n",
            " 'Loss/localization_loss': 0.01468087,\n",
            " 'Loss/regularization_loss': 0.1127992,\n",
            " 'Loss/total_loss': 0.1762199,\n",
            " 'learning_rate': 0.077449396}\n",
            "INFO:tensorflow:Step 6700 per-step time 0.620s\n",
            "I0603 05:48:15.764920 139663206823808 model_lib_v2.py:707] Step 6700 per-step time 0.620s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.034718186,\n",
            " 'Loss/localization_loss': 0.008282571,\n",
            " 'Loss/regularization_loss': 0.112271845,\n",
            " 'Loss/total_loss': 0.1552726,\n",
            " 'learning_rate': 0.077358514}\n",
            "I0603 05:48:15.765236 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.034718186,\n",
            " 'Loss/localization_loss': 0.008282571,\n",
            " 'Loss/regularization_loss': 0.112271845,\n",
            " 'Loss/total_loss': 0.1552726,\n",
            " 'learning_rate': 0.077358514}\n",
            "INFO:tensorflow:Step 6800 per-step time 0.621s\n",
            "I0603 05:49:17.897176 139663206823808 model_lib_v2.py:707] Step 6800 per-step time 0.621s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.041094217,\n",
            " 'Loss/localization_loss': 0.010429004,\n",
            " 'Loss/regularization_loss': 0.11173813,\n",
            " 'Loss/total_loss': 0.16326135,\n",
            " 'learning_rate': 0.0772661}\n",
            "I0603 05:49:17.897459 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.041094217,\n",
            " 'Loss/localization_loss': 0.010429004,\n",
            " 'Loss/regularization_loss': 0.11173813,\n",
            " 'Loss/total_loss': 0.16326135,\n",
            " 'learning_rate': 0.0772661}\n",
            "INFO:tensorflow:Step 6900 per-step time 0.625s\n",
            "I0603 05:50:20.416152 139663206823808 model_lib_v2.py:707] Step 6900 per-step time 0.625s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.055028327,\n",
            " 'Loss/localization_loss': 0.010901028,\n",
            " 'Loss/regularization_loss': 0.111286074,\n",
            " 'Loss/total_loss': 0.17721543,\n",
            " 'learning_rate': 0.077172145}\n",
            "I0603 05:50:20.416466 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.055028327,\n",
            " 'Loss/localization_loss': 0.010901028,\n",
            " 'Loss/regularization_loss': 0.111286074,\n",
            " 'Loss/total_loss': 0.17721543,\n",
            " 'learning_rate': 0.077172145}\n",
            "INFO:tensorflow:Step 7000 per-step time 0.623s\n",
            "I0603 05:51:22.688875 139663206823808 model_lib_v2.py:707] Step 7000 per-step time 0.623s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.04868238,\n",
            " 'Loss/localization_loss': 0.016616168,\n",
            " 'Loss/regularization_loss': 0.110811055,\n",
            " 'Loss/total_loss': 0.17610961,\n",
            " 'learning_rate': 0.07707667}\n",
            "I0603 05:51:22.689164 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.04868238,\n",
            " 'Loss/localization_loss': 0.016616168,\n",
            " 'Loss/regularization_loss': 0.110811055,\n",
            " 'Loss/total_loss': 0.17610961,\n",
            " 'learning_rate': 0.07707667}\n",
            "INFO:tensorflow:Step 7100 per-step time 0.630s\n",
            "I0603 05:52:25.697750 139663206823808 model_lib_v2.py:707] Step 7100 per-step time 0.630s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.03452051,\n",
            " 'Loss/localization_loss': 0.010950803,\n",
            " 'Loss/regularization_loss': 0.11031248,\n",
            " 'Loss/total_loss': 0.15578379,\n",
            " 'learning_rate': 0.07697967}\n",
            "I0603 05:52:25.698067 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.03452051,\n",
            " 'Loss/localization_loss': 0.010950803,\n",
            " 'Loss/regularization_loss': 0.11031248,\n",
            " 'Loss/total_loss': 0.15578379,\n",
            " 'learning_rate': 0.07697967}\n",
            "INFO:tensorflow:Step 7200 per-step time 0.624s\n",
            "I0603 05:53:28.094861 139663206823808 model_lib_v2.py:707] Step 7200 per-step time 0.624s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.034592543,\n",
            " 'Loss/localization_loss': 0.010291509,\n",
            " 'Loss/regularization_loss': 0.10972705,\n",
            " 'Loss/total_loss': 0.1546111,\n",
            " 'learning_rate': 0.07688115}\n",
            "I0603 05:53:28.095168 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.034592543,\n",
            " 'Loss/localization_loss': 0.010291509,\n",
            " 'Loss/regularization_loss': 0.10972705,\n",
            " 'Loss/total_loss': 0.1546111,\n",
            " 'learning_rate': 0.07688115}\n",
            "INFO:tensorflow:Step 7300 per-step time 0.622s\n",
            "I0603 05:54:30.296401 139663206823808 model_lib_v2.py:707] Step 7300 per-step time 0.622s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.038052417,\n",
            " 'Loss/localization_loss': 0.0057947705,\n",
            " 'Loss/regularization_loss': 0.109145515,\n",
            " 'Loss/total_loss': 0.1529927,\n",
            " 'learning_rate': 0.07678111}\n",
            "I0603 05:54:30.296712 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.038052417,\n",
            " 'Loss/localization_loss': 0.0057947705,\n",
            " 'Loss/regularization_loss': 0.109145515,\n",
            " 'Loss/total_loss': 0.1529927,\n",
            " 'learning_rate': 0.07678111}\n",
            "INFO:tensorflow:Step 7400 per-step time 0.620s\n",
            "I0603 05:55:32.309617 139663206823808 model_lib_v2.py:707] Step 7400 per-step time 0.620s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.035436418,\n",
            " 'Loss/localization_loss': 0.0070417933,\n",
            " 'Loss/regularization_loss': 0.108555615,\n",
            " 'Loss/total_loss': 0.15103382,\n",
            " 'learning_rate': 0.076679565}\n",
            "I0603 05:55:32.309896 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.035436418,\n",
            " 'Loss/localization_loss': 0.0070417933,\n",
            " 'Loss/regularization_loss': 0.108555615,\n",
            " 'Loss/total_loss': 0.15103382,\n",
            " 'learning_rate': 0.076679565}\n",
            "INFO:tensorflow:Step 7500 per-step time 0.624s\n",
            "I0603 05:56:34.701775 139663206823808 model_lib_v2.py:707] Step 7500 per-step time 0.624s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.038595237,\n",
            " 'Loss/localization_loss': 0.009698096,\n",
            " 'Loss/regularization_loss': 0.10797821,\n",
            " 'Loss/total_loss': 0.15627155,\n",
            " 'learning_rate': 0.0765765}\n",
            "I0603 05:56:34.702143 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.038595237,\n",
            " 'Loss/localization_loss': 0.009698096,\n",
            " 'Loss/regularization_loss': 0.10797821,\n",
            " 'Loss/total_loss': 0.15627155,\n",
            " 'learning_rate': 0.0765765}\n",
            "INFO:tensorflow:Step 7600 per-step time 0.626s\n",
            "I0603 05:57:37.254779 139663206823808 model_lib_v2.py:707] Step 7600 per-step time 0.626s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.030141361,\n",
            " 'Loss/localization_loss': 0.0062143616,\n",
            " 'Loss/regularization_loss': 0.10739327,\n",
            " 'Loss/total_loss': 0.143749,\n",
            " 'learning_rate': 0.07647194}\n",
            "I0603 05:57:37.255087 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.030141361,\n",
            " 'Loss/localization_loss': 0.0062143616,\n",
            " 'Loss/regularization_loss': 0.10739327,\n",
            " 'Loss/total_loss': 0.143749,\n",
            " 'learning_rate': 0.07647194}\n",
            "INFO:tensorflow:Step 7700 per-step time 0.622s\n",
            "I0603 05:58:39.436682 139663206823808 model_lib_v2.py:707] Step 7700 per-step time 0.622s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.041468196,\n",
            " 'Loss/localization_loss': 0.012620876,\n",
            " 'Loss/regularization_loss': 0.10681073,\n",
            " 'Loss/total_loss': 0.1608998,\n",
            " 'learning_rate': 0.07636588}\n",
            "I0603 05:58:39.436993 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.041468196,\n",
            " 'Loss/localization_loss': 0.012620876,\n",
            " 'Loss/regularization_loss': 0.10681073,\n",
            " 'Loss/total_loss': 0.1608998,\n",
            " 'learning_rate': 0.07636588}\n",
            "INFO:tensorflow:Step 7800 per-step time 0.624s\n",
            "I0603 05:59:41.825783 139663206823808 model_lib_v2.py:707] Step 7800 per-step time 0.624s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.033013023,\n",
            " 'Loss/localization_loss': 0.0071458598,\n",
            " 'Loss/regularization_loss': 0.10623214,\n",
            " 'Loss/total_loss': 0.14639102,\n",
            " 'learning_rate': 0.07625833}\n",
            "I0603 05:59:41.826079 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.033013023,\n",
            " 'Loss/localization_loss': 0.0071458598,\n",
            " 'Loss/regularization_loss': 0.10623214,\n",
            " 'Loss/total_loss': 0.14639102,\n",
            " 'learning_rate': 0.07625833}\n",
            "INFO:tensorflow:Step 7900 per-step time 0.625s\n",
            "I0603 06:00:44.302094 139663206823808 model_lib_v2.py:707] Step 7900 per-step time 0.625s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.033310045,\n",
            " 'Loss/localization_loss': 0.008538589,\n",
            " 'Loss/regularization_loss': 0.10565713,\n",
            " 'Loss/total_loss': 0.14750576,\n",
            " 'learning_rate': 0.07614928}\n",
            "I0603 06:00:44.302380 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.033310045,\n",
            " 'Loss/localization_loss': 0.008538589,\n",
            " 'Loss/regularization_loss': 0.10565713,\n",
            " 'Loss/total_loss': 0.14750576,\n",
            " 'learning_rate': 0.07614928}\n",
            "INFO:tensorflow:Step 8000 per-step time 0.624s\n",
            "I0603 06:01:46.692231 139663206823808 model_lib_v2.py:707] Step 8000 per-step time 0.624s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.03214059,\n",
            " 'Loss/localization_loss': 0.0072016083,\n",
            " 'Loss/regularization_loss': 0.105091006,\n",
            " 'Loss/total_loss': 0.1444332,\n",
            " 'learning_rate': 0.07603875}\n",
            "I0603 06:01:46.692535 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.03214059,\n",
            " 'Loss/localization_loss': 0.0072016083,\n",
            " 'Loss/regularization_loss': 0.105091006,\n",
            " 'Loss/total_loss': 0.1444332,\n",
            " 'learning_rate': 0.07603875}\n",
            "INFO:tensorflow:Step 8100 per-step time 0.627s\n",
            "I0603 06:02:49.352575 139663206823808 model_lib_v2.py:707] Step 8100 per-step time 0.627s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.027684577,\n",
            " 'Loss/localization_loss': 0.005891834,\n",
            " 'Loss/regularization_loss': 0.10451754,\n",
            " 'Loss/total_loss': 0.13809395,\n",
            " 'learning_rate': 0.07592674}\n",
            "I0603 06:02:49.352865 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.027684577,\n",
            " 'Loss/localization_loss': 0.005891834,\n",
            " 'Loss/regularization_loss': 0.10451754,\n",
            " 'Loss/total_loss': 0.13809395,\n",
            " 'learning_rate': 0.07592674}\n",
            "INFO:tensorflow:Step 8200 per-step time 0.622s\n",
            "I0603 06:03:51.578252 139663206823808 model_lib_v2.py:707] Step 8200 per-step time 0.622s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.032018095,\n",
            " 'Loss/localization_loss': 0.006460057,\n",
            " 'Loss/regularization_loss': 0.103960104,\n",
            " 'Loss/total_loss': 0.14243826,\n",
            " 'learning_rate': 0.075813256}\n",
            "I0603 06:03:51.578551 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.032018095,\n",
            " 'Loss/localization_loss': 0.006460057,\n",
            " 'Loss/regularization_loss': 0.103960104,\n",
            " 'Loss/total_loss': 0.14243826,\n",
            " 'learning_rate': 0.075813256}\n",
            "INFO:tensorflow:Step 8300 per-step time 0.622s\n",
            "I0603 06:04:53.789443 139663206823808 model_lib_v2.py:707] Step 8300 per-step time 0.622s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.043493386,\n",
            " 'Loss/localization_loss': 0.00934923,\n",
            " 'Loss/regularization_loss': 0.10340119,\n",
            " 'Loss/total_loss': 0.1562438,\n",
            " 'learning_rate': 0.07569829}\n",
            "I0603 06:04:53.789738 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.043493386,\n",
            " 'Loss/localization_loss': 0.00934923,\n",
            " 'Loss/regularization_loss': 0.10340119,\n",
            " 'Loss/total_loss': 0.1562438,\n",
            " 'learning_rate': 0.07569829}\n",
            "INFO:tensorflow:Step 8400 per-step time 0.622s\n",
            "I0603 06:05:56.002444 139663206823808 model_lib_v2.py:707] Step 8400 per-step time 0.622s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.037409388,\n",
            " 'Loss/localization_loss': 0.011311782,\n",
            " 'Loss/regularization_loss': 0.10286048,\n",
            " 'Loss/total_loss': 0.15158165,\n",
            " 'learning_rate': 0.07558186}\n",
            "I0603 06:05:56.002758 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.037409388,\n",
            " 'Loss/localization_loss': 0.011311782,\n",
            " 'Loss/regularization_loss': 0.10286048,\n",
            " 'Loss/total_loss': 0.15158165,\n",
            " 'learning_rate': 0.07558186}\n",
            "INFO:tensorflow:Step 8500 per-step time 0.623s\n",
            "I0603 06:06:58.280206 139663206823808 model_lib_v2.py:707] Step 8500 per-step time 0.623s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.040354803,\n",
            " 'Loss/localization_loss': 0.010649693,\n",
            " 'Loss/regularization_loss': 0.102304764,\n",
            " 'Loss/total_loss': 0.15330926,\n",
            " 'learning_rate': 0.07546397}\n",
            "I0603 06:06:58.280513 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.040354803,\n",
            " 'Loss/localization_loss': 0.010649693,\n",
            " 'Loss/regularization_loss': 0.102304764,\n",
            " 'Loss/total_loss': 0.15330926,\n",
            " 'learning_rate': 0.07546397}\n",
            "INFO:tensorflow:Step 8600 per-step time 0.623s\n",
            "I0603 06:08:00.599445 139663206823808 model_lib_v2.py:707] Step 8600 per-step time 0.623s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.034964282,\n",
            " 'Loss/localization_loss': 0.011247336,\n",
            " 'Loss/regularization_loss': 0.1017514,\n",
            " 'Loss/total_loss': 0.14796302,\n",
            " 'learning_rate': 0.075344615}\n",
            "I0603 06:08:00.599738 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.034964282,\n",
            " 'Loss/localization_loss': 0.011247336,\n",
            " 'Loss/regularization_loss': 0.1017514,\n",
            " 'Loss/total_loss': 0.14796302,\n",
            " 'learning_rate': 0.075344615}\n",
            "INFO:tensorflow:Step 8700 per-step time 0.624s\n",
            "I0603 06:09:02.960044 139663206823808 model_lib_v2.py:707] Step 8700 per-step time 0.624s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.02669746,\n",
            " 'Loss/localization_loss': 0.0076989494,\n",
            " 'Loss/regularization_loss': 0.101216406,\n",
            " 'Loss/total_loss': 0.13561282,\n",
            " 'learning_rate': 0.07522382}\n",
            "I0603 06:09:02.960333 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.02669746,\n",
            " 'Loss/localization_loss': 0.0076989494,\n",
            " 'Loss/regularization_loss': 0.101216406,\n",
            " 'Loss/total_loss': 0.13561282,\n",
            " 'learning_rate': 0.07522382}\n",
            "INFO:tensorflow:Step 8800 per-step time 0.622s\n",
            "I0603 06:10:05.135115 139663206823808 model_lib_v2.py:707] Step 8800 per-step time 0.622s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.2908526,\n",
            " 'Loss/localization_loss': 0.048381023,\n",
            " 'Loss/regularization_loss': 0.10288817,\n",
            " 'Loss/total_loss': 0.4421218,\n",
            " 'learning_rate': 0.07510157}\n",
            "I0603 06:10:05.135422 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.2908526,\n",
            " 'Loss/localization_loss': 0.048381023,\n",
            " 'Loss/regularization_loss': 0.10288817,\n",
            " 'Loss/total_loss': 0.4421218,\n",
            " 'learning_rate': 0.07510157}\n",
            "INFO:tensorflow:Step 8900 per-step time 0.624s\n",
            "I0603 06:11:07.512965 139663206823808 model_lib_v2.py:707] Step 8900 per-step time 0.624s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.061228022,\n",
            " 'Loss/localization_loss': 0.02252489,\n",
            " 'Loss/regularization_loss': 0.10394347,\n",
            " 'Loss/total_loss': 0.18769638,\n",
            " 'learning_rate': 0.074977875}\n",
            "I0603 06:11:07.513262 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.061228022,\n",
            " 'Loss/localization_loss': 0.02252489,\n",
            " 'Loss/regularization_loss': 0.10394347,\n",
            " 'Loss/total_loss': 0.18769638,\n",
            " 'learning_rate': 0.074977875}\n",
            "INFO:tensorflow:Step 9000 per-step time 0.625s\n",
            "I0603 06:12:09.974028 139663206823808 model_lib_v2.py:707] Step 9000 per-step time 0.625s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.044779323,\n",
            " 'Loss/localization_loss': 0.010455762,\n",
            " 'Loss/regularization_loss': 0.10348389,\n",
            " 'Loss/total_loss': 0.15871897,\n",
            " 'learning_rate': 0.07485275}\n",
            "I0603 06:12:09.974365 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.044779323,\n",
            " 'Loss/localization_loss': 0.010455762,\n",
            " 'Loss/regularization_loss': 0.10348389,\n",
            " 'Loss/total_loss': 0.15871897,\n",
            " 'learning_rate': 0.07485275}\n",
            "INFO:tensorflow:Step 9100 per-step time 0.626s\n",
            "I0603 06:13:12.622889 139663206823808 model_lib_v2.py:707] Step 9100 per-step time 0.626s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.039906446,\n",
            " 'Loss/localization_loss': 0.011499175,\n",
            " 'Loss/regularization_loss': 0.10294073,\n",
            " 'Loss/total_loss': 0.15434635,\n",
            " 'learning_rate': 0.07472619}\n",
            "I0603 06:13:12.623207 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.039906446,\n",
            " 'Loss/localization_loss': 0.011499175,\n",
            " 'Loss/regularization_loss': 0.10294073,\n",
            " 'Loss/total_loss': 0.15434635,\n",
            " 'learning_rate': 0.07472619}\n",
            "INFO:tensorflow:Step 9200 per-step time 0.623s\n",
            "I0603 06:14:14.971747 139663206823808 model_lib_v2.py:707] Step 9200 per-step time 0.623s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.041054428,\n",
            " 'Loss/localization_loss': 0.009822257,\n",
            " 'Loss/regularization_loss': 0.10239932,\n",
            " 'Loss/total_loss': 0.153276,\n",
            " 'learning_rate': 0.07459819}\n",
            "I0603 06:14:14.972066 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.041054428,\n",
            " 'Loss/localization_loss': 0.009822257,\n",
            " 'Loss/regularization_loss': 0.10239932,\n",
            " 'Loss/total_loss': 0.153276,\n",
            " 'learning_rate': 0.07459819}\n",
            "INFO:tensorflow:Step 9300 per-step time 0.627s\n",
            "I0603 06:15:17.637069 139663206823808 model_lib_v2.py:707] Step 9300 per-step time 0.627s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.03590918,\n",
            " 'Loss/localization_loss': 0.013284839,\n",
            " 'Loss/regularization_loss': 0.101868495,\n",
            " 'Loss/total_loss': 0.15106252,\n",
            " 'learning_rate': 0.074468784}\n",
            "I0603 06:15:17.637362 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.03590918,\n",
            " 'Loss/localization_loss': 0.013284839,\n",
            " 'Loss/regularization_loss': 0.101868495,\n",
            " 'Loss/total_loss': 0.15106252,\n",
            " 'learning_rate': 0.074468784}\n",
            "INFO:tensorflow:Step 9400 per-step time 0.625s\n",
            "I0603 06:16:20.138351 139663206823808 model_lib_v2.py:707] Step 9400 per-step time 0.625s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.03954145,\n",
            " 'Loss/localization_loss': 0.007312452,\n",
            " 'Loss/regularization_loss': 0.10133729,\n",
            " 'Loss/total_loss': 0.14819118,\n",
            " 'learning_rate': 0.074337944}\n",
            "I0603 06:16:20.138645 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.03954145,\n",
            " 'Loss/localization_loss': 0.007312452,\n",
            " 'Loss/regularization_loss': 0.10133729,\n",
            " 'Loss/total_loss': 0.14819118,\n",
            " 'learning_rate': 0.074337944}\n",
            "INFO:tensorflow:Step 9500 per-step time 0.622s\n",
            "I0603 06:17:22.336456 139663206823808 model_lib_v2.py:707] Step 9500 per-step time 0.622s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.036417045,\n",
            " 'Loss/localization_loss': 0.007262192,\n",
            " 'Loss/regularization_loss': 0.10080893,\n",
            " 'Loss/total_loss': 0.14448817,\n",
            " 'learning_rate': 0.074205704}\n",
            "I0603 06:17:22.336748 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.036417045,\n",
            " 'Loss/localization_loss': 0.007262192,\n",
            " 'Loss/regularization_loss': 0.10080893,\n",
            " 'Loss/total_loss': 0.14448817,\n",
            " 'learning_rate': 0.074205704}\n",
            "INFO:tensorflow:Step 9600 per-step time 0.622s\n",
            "I0603 06:18:24.521198 139663206823808 model_lib_v2.py:707] Step 9600 per-step time 0.622s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.037432734,\n",
            " 'Loss/localization_loss': 0.008536372,\n",
            " 'Loss/regularization_loss': 0.100287,\n",
            " 'Loss/total_loss': 0.1462561,\n",
            " 'learning_rate': 0.07407206}\n",
            "I0603 06:18:24.521550 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.037432734,\n",
            " 'Loss/localization_loss': 0.008536372,\n",
            " 'Loss/regularization_loss': 0.100287,\n",
            " 'Loss/total_loss': 0.1462561,\n",
            " 'learning_rate': 0.07407206}\n",
            "INFO:tensorflow:Step 9700 per-step time 0.627s\n",
            "I0603 06:19:27.219464 139663206823808 model_lib_v2.py:707] Step 9700 per-step time 0.627s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.037110057,\n",
            " 'Loss/localization_loss': 0.012303173,\n",
            " 'Loss/regularization_loss': 0.09975548,\n",
            " 'Loss/total_loss': 0.14916871,\n",
            " 'learning_rate': 0.073937014}\n",
            "I0603 06:19:27.219753 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.037110057,\n",
            " 'Loss/localization_loss': 0.012303173,\n",
            " 'Loss/regularization_loss': 0.09975548,\n",
            " 'Loss/total_loss': 0.14916871,\n",
            " 'learning_rate': 0.073937014}\n",
            "INFO:tensorflow:Step 9800 per-step time 0.621s\n",
            "I0603 06:20:29.288288 139663206823808 model_lib_v2.py:707] Step 9800 per-step time 0.621s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.03297572,\n",
            " 'Loss/localization_loss': 0.00738374,\n",
            " 'Loss/regularization_loss': 0.09922445,\n",
            " 'Loss/total_loss': 0.13958392,\n",
            " 'learning_rate': 0.07380057}\n",
            "I0603 06:20:29.288599 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.03297572,\n",
            " 'Loss/localization_loss': 0.00738374,\n",
            " 'Loss/regularization_loss': 0.09922445,\n",
            " 'Loss/total_loss': 0.13958392,\n",
            " 'learning_rate': 0.07380057}\n",
            "INFO:tensorflow:Step 9900 per-step time 0.624s\n",
            "I0603 06:21:31.692332 139663206823808 model_lib_v2.py:707] Step 9900 per-step time 0.624s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.03956324,\n",
            " 'Loss/localization_loss': 0.008909884,\n",
            " 'Loss/regularization_loss': 0.098703444,\n",
            " 'Loss/total_loss': 0.14717656,\n",
            " 'learning_rate': 0.073662736}\n",
            "I0603 06:21:31.692629 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.03956324,\n",
            " 'Loss/localization_loss': 0.008909884,\n",
            " 'Loss/regularization_loss': 0.098703444,\n",
            " 'Loss/total_loss': 0.14717656,\n",
            " 'learning_rate': 0.073662736}\n",
            "INFO:tensorflow:Step 10000 per-step time 0.624s\n",
            "I0603 06:22:34.142856 139663206823808 model_lib_v2.py:707] Step 10000 per-step time 0.624s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.041095868,\n",
            " 'Loss/localization_loss': 0.010115361,\n",
            " 'Loss/regularization_loss': 0.09818704,\n",
            " 'Loss/total_loss': 0.14939827,\n",
            " 'learning_rate': 0.07352352}\n",
            "I0603 06:22:34.143164 139663206823808 model_lib_v2.py:708] {'Loss/classification_loss': 0.041095868,\n",
            " 'Loss/localization_loss': 0.010115361,\n",
            " 'Loss/regularization_loss': 0.09818704,\n",
            " 'Loss/total_loss': 0.14939827,\n",
            " 'learning_rate': 0.07352352}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Export model\n",
        "%cd /content/gdrive/MyDrive/models/research\n",
        "%cp /content/gdrive/MyDrive/models/research/object_detection/exporter_main_v2.py .\n",
        "\n",
        "!python exporter_main_v2.py \\\n",
        "--trained_checkpoint_dir=/content/gdrive/MyDrive/output_model \\\n",
        "--pipeline_config_path=/content/gdrive/MyDrive/pretrained/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config \\\n",
        "--output_directory=/content/gdrive/MyDrive/export_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PM8A-rzC07Xt",
        "outputId": "81e18bd6-1c9c-4e46-cbe0-be0d32217ac7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/models/research\n",
            "2022-06-03 06:23:37.177791: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:458: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.map_fn(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
            "W0603 06:23:37.325850 140602229225344 deprecation.py:615] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:458: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.map_fn(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
            "2022-06-03 06:23:56.961345: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7fdfe0256950>, because it is not built.\n",
            "W0603 06:24:01.695882 140602229225344 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7fdfe0256950>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7fdff405ff90>, because it is not built.\n",
            "W0603 06:24:01.977779 140602229225344 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7fdff405ff90>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fdf61d5f0d0>, because it is not built.\n",
            "W0603 06:24:01.978009 140602229225344 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fdf61d5f0d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fdf61d5fc10>, because it is not built.\n",
            "W0603 06:24:01.978124 140602229225344 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fdf61d5fc10>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7fdf61d5fd10>, because it is not built.\n",
            "W0603 06:24:01.978212 140602229225344 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7fdf61d5fd10>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fdf61f25b90>, because it is not built.\n",
            "W0603 06:24:01.978300 140602229225344 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fdf61f25b90>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fdf61f2c590>, because it is not built.\n",
            "W0603 06:24:01.978387 140602229225344 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fdf61f2c590>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7fdf61de5150>, because it is not built.\n",
            "W0603 06:24:01.978470 140602229225344 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7fdf61de5150>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fdf61da52d0>, because it is not built.\n",
            "W0603 06:24:01.978548 140602229225344 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fdf61da52d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fdf61da5450>, because it is not built.\n",
            "W0603 06:24:01.978625 140602229225344 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fdf61da5450>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7fdf762ae890>, because it is not built.\n",
            "W0603 06:24:01.978705 140602229225344 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7fdf762ae890>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fdf61da5b50>, because it is not built.\n",
            "W0603 06:24:01.978781 140602229225344 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fdf61da5b50>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fdf61f15790>, because it is not built.\n",
            "W0603 06:24:01.978857 140602229225344 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fdf61f15790>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fdfe01108d0>, because it is not built.\n",
            "W0603 06:24:01.978932 140602229225344 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fdfe01108d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fdf61db2510>, because it is not built.\n",
            "W0603 06:24:01.979052 140602229225344 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fdf61db2510>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fdf61db27d0>, because it is not built.\n",
            "W0603 06:24:01.979140 140602229225344 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fdf61db27d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fdf61db2ad0>, because it is not built.\n",
            "W0603 06:24:01.979221 140602229225344 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fdf61db2ad0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fdf61d67550>, because it is not built.\n",
            "W0603 06:24:01.979300 140602229225344 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fdf61d67550>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fdf61db2790>, because it is not built.\n",
            "W0603 06:24:01.979378 140602229225344 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fdf61db2790>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fdf61db2950>, because it is not built.\n",
            "W0603 06:24:01.979457 140602229225344 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fdf61db2950>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fdf61df1d50>, because it is not built.\n",
            "W0603 06:24:01.979536 140602229225344 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fdf61df1d50>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fdfe0110910>, because it is not built.\n",
            "W0603 06:24:01.979621 140602229225344 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fdfe0110910>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fdf61d7d610>, because it is not built.\n",
            "W0603 06:24:01.979701 140602229225344 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fdf61d7d610>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fdf61f15950>, because it is not built.\n",
            "W0603 06:24:01.979783 140602229225344 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fdf61f15950>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fdf76644150>, because it is not built.\n",
            "W0603 06:24:01.979862 140602229225344 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fdf76644150>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fdf61d7d290>, because it is not built.\n",
            "W0603 06:24:01.979941 140602229225344 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fdf61d7d290>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fdf61d7d590>, because it is not built.\n",
            "W0603 06:24:01.980044 140602229225344 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fdf61d7d590>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fdf61ed4c90>, because it is not built.\n",
            "W0603 06:24:01.980127 140602229225344 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fdf61ed4c90>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fdf61cfe1d0>, because it is not built.\n",
            "W0603 06:24:01.980217 140602229225344 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fdf61cfe1d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fdf61cd93d0>, because it is not built.\n",
            "W0603 06:24:01.980293 140602229225344 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fdf61cd93d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fdf61ce9190>, because it is not built.\n",
            "W0603 06:24:01.980369 140602229225344 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fdf61ce9190>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fdf61e5dd90>, because it is not built.\n",
            "W0603 06:24:01.980446 140602229225344 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fdf61e5dd90>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fdf61ce9f90>, because it is not built.\n",
            "W0603 06:24:01.980523 140602229225344 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fdf61ce9f90>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fdf61ce9890>, because it is not built.\n",
            "W0603 06:24:01.980603 140602229225344 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fdf61ce9890>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fdf61db9210>, because it is not built.\n",
            "W0603 06:24:01.980679 140602229225344 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fdf61db9210>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fdf61db9790>, because it is not built.\n",
            "W0603 06:24:01.980757 140602229225344 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fdf61db9790>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fdf61db96d0>, because it is not built.\n",
            "W0603 06:24:01.980837 140602229225344 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fdf61db96d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fdfe0110950>, because it is not built.\n",
            "W0603 06:24:01.980917 140602229225344 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fdfe0110950>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fdf760af1d0>, because it is not built.\n",
            "W0603 06:24:01.981011 140602229225344 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fdf760af1d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fdf61f35390>, because it is not built.\n",
            "W0603 06:24:01.981093 140602229225344 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fdf61f35390>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fdf61f7c310>, because it is not built.\n",
            "W0603 06:24:01.981169 140602229225344 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fdf61f7c310>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fdf76676950>, because it is not built.\n",
            "W0603 06:24:01.981246 140602229225344 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fdf76676950>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fdf61d44890>, because it is not built.\n",
            "W0603 06:24:01.981322 140602229225344 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fdf61d44890>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fdf61d44990>, because it is not built.\n",
            "W0603 06:24:01.981398 140602229225344 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fdf61d44990>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fdf61d44fd0>, because it is not built.\n",
            "W0603 06:24:02.022932 140602229225344 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fdf61d44fd0>, because it is not built.\n",
            "W0603 06:24:17.759371 140602229225344 save.py:265] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalClassHead_layer_call_fn while saving (showing 5 of 104). These functions will not be directly callable after loading.\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/MyDrive/export_model/saved_model/assets\n",
            "I0603 06:24:23.183264 140602229225344 builder_impl.py:780] Assets written to: /content/gdrive/MyDrive/export_model/saved_model/assets\n",
            "INFO:tensorflow:Writing pipeline config file to /content/gdrive/MyDrive/export_model/pipeline.config\n",
            "I0603 06:24:23.788223 140602229225344 config_util.py:254] Writing pipeline config file to /content/gdrive/MyDrive/export_model/pipeline.config\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-b5tiBfm099U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}